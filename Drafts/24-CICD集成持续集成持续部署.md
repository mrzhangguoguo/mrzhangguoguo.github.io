---
layout: post
title: "CI/CDé›†æˆï¼šæŒç»­é›†æˆæŒç»­éƒ¨ç½²ï¼Œè®©Claude Codeæˆä¸ºDevOpsæµæ°´çº¿çš„æ™ºèƒ½æ ¸å¿ƒ"
date: 2025-08-17 08:00:00 +0800
tags: [Claude Code, CI/CD, æŒç»­é›†æˆ, æŒç»­éƒ¨ç½², DevOps, è‡ªåŠ¨åŒ–]
excerpt: "æ·±å…¥æ¢ç´¢Claude Codeåœ¨CI/CDæµæ°´çº¿ä¸­çš„é›†æˆåº”ç”¨ï¼Œä»ä»£ç æäº¤åˆ°ç”Ÿäº§éƒ¨ç½²ï¼Œæ„å»ºæ™ºèƒ½åŒ–çš„DevOpså·¥ä½œæµï¼Œè®©AIåŠ©æ‰‹æˆä¸ºæ•´ä¸ªè½¯ä»¶äº¤ä»˜é“¾è·¯çš„æ™ºèƒ½å¼•æ“ã€‚"
---

## å¼•è¨€ï¼šä»ä»£ç åˆ°ç”Ÿäº§çš„æ™ºèƒ½åŒ–ä¹‹è·¯

> "è½¯ä»¶äº¤ä»˜ä¸æ˜¯ç»ˆç‚¹ï¼Œè€Œæ˜¯ä»·å€¼åˆ›é€ çš„èµ·ç‚¹ã€‚" â€”â€” Jez Humble

åœ¨ç°ä»£è½¯ä»¶å¼€å‘ä¸­ï¼Œ**ä»ä»£ç æäº¤åˆ°ç”Ÿäº§éƒ¨ç½²çš„é€Ÿåº¦å’Œè´¨é‡ç›´æ¥å†³å®šäº†å›¢é˜Ÿçš„ç«äº‰åŠ›**ã€‚ä¼ ç»Ÿçš„CI/CDæµæ°´çº¿è™½ç„¶å®ç°äº†è‡ªåŠ¨åŒ–ï¼Œä½†ç¼ºå°‘æ™ºèƒ½å†³ç­–å’Œè‡ªé€‚åº”ä¼˜åŒ–èƒ½åŠ›ã€‚Claude Codeçš„å¼•å…¥å½»åº•æ”¹å˜äº†è¿™ä¸€çŠ¶å†µâ€”â€”è®©AIæˆä¸ºDevOpsæµæ°´çº¿çš„æ™ºèƒ½å¤§è„‘ã€‚

æƒ³è±¡ä¸€ä¸‹ï¼šå½“å¼€å‘è€…æäº¤ä»£ç æ—¶ï¼ŒClaude Codeä¸ä»…èƒ½è‡ªåŠ¨å®¡æŸ¥ä»£ç è´¨é‡ï¼Œè¿˜èƒ½é¢„æµ‹æ½œåœ¨é£é™©ã€æ™ºèƒ½è°ƒæ•´æµ‹è¯•ç­–ç•¥ã€åŠ¨æ€ä¼˜åŒ–éƒ¨ç½²æ–¹æ¡ˆï¼Œç”šè‡³åœ¨å‡ºç°é—®é¢˜æ—¶è‡ªä¸»å›æ»šå’Œä¿®å¤ã€‚è¿™å°±æ˜¯AIé©±åŠ¨çš„æ™ºèƒ½DevOpsçš„é­…åŠ›ã€‚

è¿™ç¯‡æ–‡ç« å°†å…¨é¢è§£æå¦‚ä½•å°†Claude Codeæ·±åº¦é›†æˆåˆ°CI/CDæµæ°´çº¿ä¸­ï¼Œæ‰“é€ çœŸæ­£æ™ºèƒ½åŒ–çš„è½¯ä»¶äº¤ä»˜ä½“ç³»ã€‚

## CI/CDç°çŠ¶ä¸æŒ‘æˆ˜

### ä¼ ç»ŸCI/CDæµæ°´çº¿çš„å±€é™

```
ä¼ ç»ŸCI/CDé¢ä¸´çš„æ ¸å¿ƒé—®é¢˜ï¼š
1. è§„åˆ™é©±åŠ¨ â†’ ç¼ºä¹æ™ºèƒ½å†³ç­–èƒ½åŠ›
2. é™æ€é…ç½® â†’ æ— æ³•æ ¹æ®æƒ…å†µè‡ªé€‚åº”
3. äººå·¥å¹²é¢„ â†’ å…³é”®èŠ‚ç‚¹éœ€è¦äººå·¥åˆ¤æ–­
4. ååº”å¼å¤„ç† â†’ é—®é¢˜å‘ç”Ÿåæ‰å“åº”
5. ç»éªŒä¾èµ– â†’ ä¾èµ–å›¢é˜Ÿç»éªŒç§¯ç´¯

å…¸å‹ç—›ç‚¹ï¼š
- ğŸ“Š æµ‹è¯•ç­–ç•¥å›ºå®šï¼Œæ— æ³•æ™ºèƒ½é€‰æ‹©é‡ç‚¹
- ğŸ”§ éƒ¨ç½²å†³ç­–ä¾èµ–äººå·¥åˆ¤æ–­
- ğŸ“ˆ ç¼ºä¹åŸºäºå†å²æ•°æ®çš„ä¼˜åŒ–
- âš ï¸ é—®é¢˜å‘ç°æ»åï¼Œå½±å“ç”¨æˆ·ä½“éªŒ
- ğŸ”„ å›æ»šå†³ç­–ç¼ºä¹æ™ºèƒ½åˆ†æ
```

### Claude Codeå¢å¼ºçš„æ™ºèƒ½CI/CD

```
AIé©±åŠ¨çš„æ™ºèƒ½CI/CDä¼˜åŠ¿ï¼š
1. æ™ºèƒ½å†³ç­– â†’ AIåˆ†æä»£ç å˜æ›´å½±å“
2. è‡ªé€‚åº”è°ƒæ•´ â†’ æ ¹æ®æƒ…å†µåŠ¨æ€ä¼˜åŒ–ç­–ç•¥
3. é¢„æµ‹æ€§åˆ†æ â†’ æå‰è¯†åˆ«æ½œåœ¨é£é™©
4. è‡ªä¸»ä¿®å¤ â†’ è‡ªåŠ¨å¤„ç†å¸¸è§é—®é¢˜
5. æŒç»­å­¦ä¹  â†’ åŸºäºå†å²æ•°æ®ä¸æ–­æ”¹è¿›

æ™ºèƒ½èƒ½åŠ›ï¼š
- ğŸ§  æ™ºèƒ½ä»£ç å®¡æŸ¥å’Œé£é™©è¯„ä¼°
- ğŸ¯ åŠ¨æ€æµ‹è¯•ç­–ç•¥é€‰æ‹©
- ğŸ“Š åŸºäºAIçš„éƒ¨ç½²å†³ç­–æ”¯æŒ
- ğŸ” å®æ—¶ç›‘æ§å’Œå¼‚å¸¸æ£€æµ‹
- ğŸ¤– è‡ªåŠ¨åŒ–é—®é¢˜è¯Šæ–­å’Œä¿®å¤
```

## CI/CDé›†æˆæ¶æ„è®¾è®¡

### 1. æ•´ä½“æ¶æ„æ¦‚è§ˆ

#### æ™ºèƒ½CI/CDæµæ°´çº¿æ¶æ„

```mermaid
graph TD
    A[å¼€å‘è€…æäº¤ä»£ç ] --> B[Claude Code æ™ºèƒ½åˆ†æ]
    B --> C[æ™ºèƒ½ä»£ç å®¡æŸ¥]
    C --> D[åŠ¨æ€æµ‹è¯•ç­–ç•¥]
    D --> E[æ™ºèƒ½æ„å»ºä¼˜åŒ–]
    E --> F[AIé©±åŠ¨éƒ¨ç½²å†³ç­–]
    F --> G[ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²]
    G --> H[å®æ—¶ç›‘æ§åˆ†æ]
    H --> I[é—®é¢˜è‡ªåŠ¨æ£€æµ‹]
    I --> J[æ™ºèƒ½ä¿®å¤/å›æ»š]
    
    subgraph "æ™ºèƒ½åˆ†æå±‚"
        B1[ä»£ç å˜æ›´åˆ†æ]
        B2[å½±å“èŒƒå›´è¯„ä¼°]
        B3[é£é™©ç­‰çº§åˆ¤æ–­]
        B4[æµ‹è¯•ç­–ç•¥æ¨è]
    end
    
    subgraph "æ‰§è¡Œå±‚"
        C1[è‡ªåŠ¨åŒ–æµ‹è¯•]
        C2[å®‰å…¨æ‰«æ]
        C3[æ€§èƒ½æµ‹è¯•]
        C4[æ„å»ºæ‰“åŒ…]
    end
    
    subgraph "éƒ¨ç½²å±‚"
        D1[è“ç»¿éƒ¨ç½²]
        D2[é‡‘ä¸é›€å‘å¸ƒ]
        D3[æ»šåŠ¨æ›´æ–°]
        D4[A/Bæµ‹è¯•]
    end
    
    subgraph "ç›‘æ§å±‚"
        E1[æ€§èƒ½ç›‘æ§]
        E2[é”™è¯¯è¿½è¸ª]
        E3[ç”¨æˆ·ä½“éªŒç›‘æ§]
        E4[ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§]
    end
    
    B --> B1
    B1 --> B2
    B2 --> B3
    B3 --> B4
    
    D --> C1
    D --> C2
    D --> C3
    D --> C4
    
    F --> D1
    F --> D2
    F --> D3
    F --> D4
    
    H --> E1
    H --> E2
    H --> E3
    H --> E4
```

### 2. æ™ºèƒ½CIé›†æˆé…ç½®

#### GitHub Actionsé›†æˆç¤ºä¾‹

```yaml
# .github/workflows/claude-ci.yml
name: Claude Code Intelligent CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * *'  # æ¯æ—¥å‡Œæ™¨2ç‚¹æ‰§è¡Œå…¨é¢æ£€æŸ¥

env:
  CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'

jobs:
  # é˜¶æ®µ1ï¼šæ™ºèƒ½ä»£ç åˆ†æ
  intelligent-analysis:
    runs-on: ubuntu-latest
    outputs:
      risk-level: ${{ steps.claude-analysis.outputs.risk-level }}
      test-strategy: ${{ steps.claude-analysis.outputs.test-strategy }}
      deployment-recommendation: ${{ steps.claude-analysis.outputs.deployment-recommendation }}
      affected-modules: ${{ steps.claude-analysis.outputs.affected-modules }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # è·å–å®Œæ•´å†å²ç”¨äºåˆ†æ
      
      - name: Setup Claude Code
        uses: anthropics/setup-claude-code@v1
        with:
          api-key: ${{ env.CLAUDE_API_KEY }}
          version: 'latest'
      
      - name: æ™ºèƒ½ä»£ç å˜æ›´åˆ†æ
        id: claude-analysis
        run: |
          echo "ğŸ§  Claude Code æ™ºèƒ½åˆ†æå¼€å§‹..."
          
          # è·å–å˜æ›´ä¿¡æ¯
          CHANGED_FILES=$(git diff --name-only HEAD~1)
          COMMIT_MESSAGE=$(git log -1 --pretty=%B)
          
          # Claude Code åˆ†æä»£ç å˜æ›´
          claude analyze-change \
            --files="$CHANGED_FILES" \
            --commit-message="$COMMIT_MESSAGE" \
            --branch=${{ github.ref_name }} \
            --output-format=json > analysis-result.json
          
          # æå–åˆ†æç»“æœ
          RISK_LEVEL=$(jq -r '.risk_level' analysis-result.json)
          TEST_STRATEGY=$(jq -r '.test_strategy' analysis-result.json)
          DEPLOYMENT_REC=$(jq -r '.deployment_recommendation' analysis-result.json)
          AFFECTED_MODULES=$(jq -r '.affected_modules | join(",")' analysis-result.json)
          
          echo "risk-level=$RISK_LEVEL" >> $GITHUB_OUTPUT
          echo "test-strategy=$TEST_STRATEGY" >> $GITHUB_OUTPUT
          echo "deployment-recommendation=$DEPLOYMENT_REC" >> $GITHUB_OUTPUT
          echo "affected-modules=$AFFECTED_MODULES" >> $GITHUB_OUTPUT
          
          echo "ğŸ“Š åˆ†æç»“æœï¼š"
          echo "  é£é™©ç­‰çº§: $RISK_LEVEL"
          echo "  æµ‹è¯•ç­–ç•¥: $TEST_STRATEGY"
          echo "  éƒ¨ç½²å»ºè®®: $DEPLOYMENT_REC"
          echo "  å½±å“æ¨¡å—: $AFFECTED_MODULES"
      
      - name: ç”Ÿæˆæ™ºèƒ½æµ‹è¯•è®¡åˆ’
        run: |
          claude generate-test-plan \
            --risk-level="${{ steps.claude-analysis.outputs.risk-level }}" \
            --affected-modules="${{ steps.claude-analysis.outputs.affected-modules }}" \
            --output-file=test-plan.json
          
          echo "ğŸ“‹ æ™ºèƒ½æµ‹è¯•è®¡åˆ’å·²ç”Ÿæˆ"
          cat test-plan.json | jq '.'
      
      - name: Upload analysis artifacts
        uses: actions/upload-artifact@v3
        with:
          name: claude-analysis
          path: |
            analysis-result.json
            test-plan.json

  # é˜¶æ®µ2ï¼šæ™ºèƒ½ä»£ç å®¡æŸ¥
  intelligent-code-review:
    runs-on: ubuntu-latest
    needs: intelligent-analysis
    if: ${{ needs.intelligent-analysis.outputs.risk-level != 'low' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Claude Code
        uses: anthropics/setup-claude-code@v1
        with:
          api-key: ${{ env.CLAUDE_API_KEY }}
      
      - name: æ™ºèƒ½ä»£ç å®¡æŸ¥
        run: |
          echo "ğŸ” å¼€å§‹æ™ºèƒ½ä»£ç å®¡æŸ¥..."
          
          # å…¨é¢ä»£ç å®¡æŸ¥
          claude review-code \
            --scope=changed-files \
            --depth=deep \
            --include-security \
            --include-performance \
            --output-format=github-comment > review-comment.md
          
          # æ£€æŸ¥æ˜¯å¦æœ‰é˜»å¡é—®é¢˜
          BLOCKING_ISSUES=$(claude review-code --scope=changed-files --check-blocking --output-format=json | jq -r '.blocking_issues | length')
          
          if [ "$BLOCKING_ISSUES" -gt 0 ]; then
            echo "âŒ å‘ç°é˜»å¡æ€§é—®é¢˜ï¼Œéœ€è¦ä¿®å¤åæ‰èƒ½ç»§ç»­"
            claude review-code --scope=changed-files --check-blocking --output-format=text
            exit 1
          fi
          
          echo "âœ… ä»£ç å®¡æŸ¥é€šè¿‡"
      
      - name: å‘å¸ƒå®¡æŸ¥è¯„è®º
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const reviewComment = fs.readFileSync('review-comment.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: reviewComment
            });

  # é˜¶æ®µ3ï¼šåŠ¨æ€æµ‹è¯•æ‰§è¡Œ
  dynamic-testing:
    runs-on: ubuntu-latest
    needs: intelligent-analysis
    strategy:
      matrix:
        test-type: ${{ fromJson(needs.intelligent-analysis.outputs.test-strategy) }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          npm ci
          pip install -r requirements.txt
      
      - name: Setup Claude Code
        uses: anthropics/setup-claude-code@v1
        with:
          api-key: ${{ env.CLAUDE_API_KEY }}
      
      - name: æ‰§è¡Œæ™ºèƒ½æµ‹è¯•
        run: |
          echo "ğŸ§ª æ‰§è¡Œæµ‹è¯•ç±»å‹: ${{ matrix.test-type }}"
          
          case "${{ matrix.test-type }}" in
            "unit")
              echo "ğŸ”¬ æ‰§è¡Œå•å…ƒæµ‹è¯•"
              claude test-runner \
                --type=unit \
                --coverage-threshold=80 \
                --parallel \
                --smart-selection
              ;;
            "integration")
              echo "ğŸ”— æ‰§è¡Œé›†æˆæµ‹è¯•"
              claude test-runner \
                --type=integration \
                --affected-modules="${{ needs.intelligent-analysis.outputs.affected-modules }}" \
                --timeout=300
              ;;
            "e2e")
              echo "ğŸ­ æ‰§è¡Œç«¯åˆ°ç«¯æµ‹è¯•"
              claude test-runner \
                --type=e2e \
                --browser=chrome \
                --headless \
                --critical-paths-only
              ;;
            "performance")
              echo "âš¡ æ‰§è¡Œæ€§èƒ½æµ‹è¯•"
              claude performance-test \
                --baseline=main \
                --threshold=10% \
                --metrics=response-time,memory,cpu
              ;;
            "security")
              echo "ğŸ”’ æ‰§è¡Œå®‰å…¨æµ‹è¯•"
              claude security-scan \
                --include-dependencies \
                --check-vulnerabilities \
                --compliance-check
              ;;
          esac
      
      - name: ä¸Šä¼ æµ‹è¯•ç»“æœ
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results-${{ matrix.test-type }}
          path: |
            test-results/
            coverage-reports/
            performance-reports/
            security-reports/

  # é˜¶æ®µ4ï¼šæ™ºèƒ½æ„å»ºä¼˜åŒ–
  intelligent-build:
    runs-on: ubuntu-latest
    needs: [intelligent-analysis, dynamic-testing]
    if: success()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup build environment
        run: |
          # æ ¹æ®é¡¹ç›®ç±»å‹è®¾ç½®æ„å»ºç¯å¢ƒ
          if [ -f "package.json" ]; then
            echo "LANG=nodejs" >> $GITHUB_ENV
          elif [ -f "requirements.txt" ]; then
            echo "LANG=python" >> $GITHUB_ENV
          elif [ -f "go.mod" ]; then
            echo "LANG=go" >> $GITHUB_ENV
          fi
      
      - name: Setup Claude Code
        uses: anthropics/setup-claude-code@v1
        with:
          api-key: ${{ env.CLAUDE_API_KEY }}
      
      - name: æ™ºèƒ½æ„å»ºä¼˜åŒ–
        run: |
          echo "ğŸ—ï¸ å¼€å§‹æ™ºèƒ½æ„å»º..."
          
          # åˆ†ææ„å»ºé…ç½®å¹¶ä¼˜åŒ–
          claude optimize-build \
            --language=${{ env.LANG }} \
            --target=production \
            --optimize-for=size,speed \
            --generate-config
          
          # æ‰§è¡Œä¼˜åŒ–åçš„æ„å»º
          claude build \
            --use-optimized-config \
            --parallel \
            --cache-enabled \
            --output-dir=dist
          
          echo "âœ… æ„å»ºå®Œæˆ"
      
      - name: æ„å»ºäº§ç‰©åˆ†æ
        run: |
          echo "ğŸ“¦ åˆ†ææ„å»ºäº§ç‰©..."
          
          claude analyze-artifacts \
            --directory=dist \
            --check-size \
            --check-security \
            --generate-report > build-analysis.json
          
          echo "æ„å»ºäº§ç‰©åˆ†æç»“æœï¼š"
          cat build-analysis.json | jq '.'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: build-artifacts
          path: |
            dist/
            build-analysis.json

  # é˜¶æ®µ5ï¼šéƒ¨ç½²å°±ç»ªæ€§æ£€æŸ¥
  deployment-readiness:
    runs-on: ubuntu-latest
    needs: [intelligent-analysis, intelligent-build]
    if: success()
    outputs:
      ready-for-deployment: ${{ steps.readiness-check.outputs.ready }}
      deployment-strategy: ${{ steps.readiness-check.outputs.strategy }}
    
    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v3
        with:
          name: claude-analysis
      
      - name: Setup Claude Code
        uses: anthropics/setup-claude-code@v1
        with:
          api-key: ${{ env.CLAUDE_API_KEY }}
      
      - name: éƒ¨ç½²å°±ç»ªæ€§æ£€æŸ¥
        id: readiness-check
        run: |
          echo "ğŸ¯ æ£€æŸ¥éƒ¨ç½²å°±ç»ªæ€§..."
          
          # ç»¼åˆåˆ†ææ‰€æœ‰æ£€æŸ¥ç»“æœ
          claude deployment-readiness-check \
            --analysis-file=analysis-result.json \
            --test-results-dir=test-results \
            --build-artifacts=dist \
            --output-format=json > readiness-result.json
          
          READY=$(jq -r '.ready' readiness-result.json)
          STRATEGY=$(jq -r '.recommended_strategy' readiness-result.json)
          
          echo "ready=$READY" >> $GITHUB_OUTPUT
          echo "strategy=$STRATEGY" >> $GITHUB_OUTPUT
          
          echo "ğŸ“Š éƒ¨ç½²å°±ç»ªæ€§æ£€æŸ¥ç»“æœï¼š"
          echo "  å°±ç»ªçŠ¶æ€: $READY"
          echo "  æ¨èç­–ç•¥: $STRATEGY"
          
          if [ "$READY" = "false" ]; then
            echo "âŒ éƒ¨ç½²æ¡ä»¶ä¸æ»¡è¶³"
            jq -r '.blocking_reasons[]' readiness-result.json
            exit 1
          fi
          
          echo "âœ… éƒ¨ç½²æ¡ä»¶æ»¡è¶³"
```

### 3. æ™ºèƒ½éƒ¨ç½²ç­–ç•¥

#### å¤šç¯å¢ƒéƒ¨ç½²é…ç½®

```yaml
# .github/workflows/claude-cd.yml
name: Claude Code Intelligent CD

on:
  workflow_run:
    workflows: ["Claude Code Intelligent CI"]
    types: [completed]
    branches: [main]

env:
  CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}

jobs:
  # æ™ºèƒ½éƒ¨ç½²å†³ç­–
  deployment-strategy:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    outputs:
      strategy: ${{ steps.deploy-strategy.outputs.strategy }}
      target-environments: ${{ steps.deploy-strategy.outputs.environments }}
      rollout-plan: ${{ steps.deploy-strategy.outputs.rollout-plan }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Claude Code
        uses: anthropics/setup-claude-code@v1
        with:
          api-key: ${{ env.CLAUDE_API_KEY }}
      
      - name: æ™ºèƒ½éƒ¨ç½²ç­–ç•¥å†³ç­–
        id: deploy-strategy
        run: |
          echo "ğŸ¯ åˆ¶å®šæ™ºèƒ½éƒ¨ç½²ç­–ç•¥..."
          
          # åˆ†æå†å²éƒ¨ç½²æ•°æ®å’Œå½“å‰å˜æ›´
          claude analyze-deployment-context \
            --branch=main \
            --include-history=30d \
            --risk-factors \
            --output-format=json > deployment-context.json
          
          # åŸºäºåˆ†æç»“æœåˆ¶å®šéƒ¨ç½²ç­–ç•¥
          claude recommend-deployment-strategy \
            --context-file=deployment-context.json \
            --target-environments=staging,production \
            --business-hours-constraint \
            --output-format=json > strategy-result.json
          
          STRATEGY=$(jq -r '.strategy' strategy-result.json)
          ENVIRONMENTS=$(jq -r '.target_environments | join(",")' strategy-result.json)
          ROLLOUT_PLAN=$(jq -r '.rollout_plan' strategy-result.json)
          
          echo "strategy=$STRATEGY" >> $GITHUB_OUTPUT
          echo "environments=$ENVIRONMENTS" >> $GITHUB_OUTPUT
          echo "rollout-plan=$ROLLOUT_PLAN" >> $GITHUB_OUTPUT
          
          echo "ğŸ“‹ éƒ¨ç½²ç­–ç•¥ï¼š"
          echo "  ç­–ç•¥ç±»å‹: $STRATEGY"
          echo "  ç›®æ ‡ç¯å¢ƒ: $ENVIRONMENTS"
          echo "  å‘å¸ƒè®¡åˆ’: $ROLLOUT_PLAN"

  # åˆ†é˜¶æ®µéƒ¨ç½²
  deploy-staging:
    runs-on: ubuntu-latest
    needs: deployment-strategy
    if: contains(needs.deployment-strategy.outputs.target-environments, 'staging')
    environment: staging
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Claude Code
        uses: anthropics/setup-claude-code@v1
        with:
          api-key: ${{ env.CLAUDE_API_KEY }}
      
      - name: éƒ¨ç½²åˆ°Stagingç¯å¢ƒ
        run: |
          echo "ğŸš€ éƒ¨ç½²åˆ° Staging ç¯å¢ƒ..."
          
          # å‡†å¤‡éƒ¨ç½²é…ç½®
          claude prepare-deployment \
            --environment=staging \
            --strategy="${{ needs.deployment-strategy.outputs.strategy }}" \
            --generate-config
          
          # æ‰§è¡Œéƒ¨ç½²
          claude deploy \
            --environment=staging \
            --config=staging-deploy.yml \
            --monitor-health \
            --timeout=600
          
          echo "âœ… Staging éƒ¨ç½²å®Œæˆ"
      
      - name: éƒ¨ç½²åéªŒè¯
        run: |
          echo "ğŸ” æ‰§è¡Œéƒ¨ç½²åéªŒè¯..."
          
          # å¥åº·æ£€æŸ¥
          claude health-check \
            --environment=staging \
            --endpoints=api,web,health \
            --timeout=300
          
          # çƒŸé›¾æµ‹è¯•
          claude smoke-test \
            --environment=staging \
            --test-suite=critical-paths \
            --parallel
          
          # æ€§èƒ½åŸºå‡†éªŒè¯
          claude performance-validation \
            --environment=staging \
            --baseline=production \
            --threshold=15%
          
          echo "âœ… éƒ¨ç½²éªŒè¯é€šè¿‡"

  # ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼ˆéœ€è¦å®¡æ‰¹ï¼‰
  deploy-production:
    runs-on: ubuntu-latest
    needs: [deployment-strategy, deploy-staging]
    if: success() && contains(needs.deployment-strategy.outputs.target-environments, 'production')
    environment: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Claude Code
        uses: anthropics/setup-claude-code@v1
        with:
          api-key: ${{ env.CLAUDE_API_KEY }}
      
      - name: ç”Ÿäº§éƒ¨ç½²å‰æ£€æŸ¥
        run: |
          echo "ğŸ” ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å‰æ£€æŸ¥..."
          
          # æœ€ç»ˆéƒ¨ç½²å°±ç»ªæ€§æ£€æŸ¥
          claude pre-production-check \
            --staging-validation=passed \
            --security-scan=passed \
            --performance-baseline=acceptable \
            --business-impact-assessment
          
          # éƒ¨ç½²æ—¶æœºæ£€æŸ¥
          claude deployment-timing-check \
            --avoid-business-hours \
            --check-traffic-patterns \
            --consider-team-availability
          
          echo "âœ… ç”Ÿäº§éƒ¨ç½²å‰æ£€æŸ¥é€šè¿‡"
      
      - name: æ™ºèƒ½ç”Ÿäº§éƒ¨ç½²
        run: |
          echo "ğŸŒŸ å¼€å§‹ç”Ÿäº§ç¯å¢ƒæ™ºèƒ½éƒ¨ç½²..."
          
          STRATEGY="${{ needs.deployment-strategy.outputs.strategy }}"
          
          case "$STRATEGY" in
            "blue-green")
              echo "ğŸ”µğŸŸ¢ æ‰§è¡Œè“ç»¿éƒ¨ç½²"
              claude deploy-blue-green \
                --environment=production \
                --health-check-endpoints \
                --traffic-switch-strategy=gradual \
                --rollback-on-failure
              ;;
            "canary")
              echo "ğŸ¤ æ‰§è¡Œé‡‘ä¸é›€éƒ¨ç½²"
              claude deploy-canary \
                --environment=production \
                --canary-percentage=5 \
                --ramp-up-duration=30m \
                --success-criteria=error-rate:1%,response-time:2s
              ;;
            "rolling")
              echo "ğŸ”„ æ‰§è¡Œæ»šåŠ¨éƒ¨ç½²"
              claude deploy-rolling \
                --environment=production \
                --batch-size=2 \
                --health-check-delay=60s \
                --max-unavailable=1
              ;;
          esac
          
          echo "âœ… ç”Ÿäº§éƒ¨ç½²å®Œæˆ"
      
      - name: éƒ¨ç½²åç›‘æ§
        run: |
          echo "ğŸ“Š å¯åŠ¨éƒ¨ç½²åç›‘æ§..."
          
          # å¯åŠ¨æ™ºèƒ½ç›‘æ§
          claude start-post-deployment-monitoring \
            --environment=production \
            --duration=2h \
            --alert-threshold=strict \
            --auto-rollback-conditions="error-rate:3%,response-time:5s"
          
          echo "ğŸ¯ ç›‘æ§å·²å¯åŠ¨ï¼Œå°†æŒç»­2å°æ—¶"

  # éƒ¨ç½²æˆåŠŸé€šçŸ¥
  deployment-notification:
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: success()
    
    steps:
      - name: Setup Claude Code
        uses: anthropics/setup-claude-code@v1
        with:
          api-key: ${{ env.CLAUDE_API_KEY }}
      
      - name: ç”Ÿæˆéƒ¨ç½²æŠ¥å‘Š
        run: |
          echo "ğŸ“Š ç”Ÿæˆéƒ¨ç½²æˆåŠŸæŠ¥å‘Š..."
          
          claude generate-deployment-report \
            --deployment-id=${{ github.run_id }} \
            --environments=staging,production \
            --include-metrics \
            --include-timeline \
            --output-format=markdown > deployment-report.md
          
          echo "éƒ¨ç½²æŠ¥å‘Šå·²ç”Ÿæˆ"
      
      - name: å‘é€é€šçŸ¥
        run: |
          # å‘é€Slacké€šçŸ¥
          claude notify \
            --channel=deployments \
            --template=deployment-success \
            --attach-report=deployment-report.md \
            --include-metrics
          
          # æ›´æ–°é¡¹ç›®dashboard
          claude update-dashboard \
            --project=main \
            --status=deployed \
            --version=${{ github.sha }} \
            --timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          
          echo "âœ… é€šçŸ¥å·²å‘é€"
```

## å®é™…åº”ç”¨åœºæ™¯

### åœºæ™¯1ï¼šæ™ºèƒ½å‘å¸ƒå†³ç­–ç³»ç»Ÿ

```bash
claude """
åˆ†æå½“å‰ä»£ç å˜æ›´çš„å‘å¸ƒé£é™©ï¼Œå¹¶æ¨èæœ€é€‚åˆçš„å‘å¸ƒç­–ç•¥ï¼š

å˜æ›´å†…å®¹ï¼š
- ä¿®å¤äº†ç”¨æˆ·ç™»å½•æ¨¡å—çš„å®‰å…¨æ¼æ´
- ä¼˜åŒ–äº†æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½  
- æ›´æ–°äº†å‰ç«¯ä¾èµ–åŒ…ç‰ˆæœ¬
- æ·»åŠ äº†æ–°çš„APIç«¯ç‚¹

è¯·è¯„ä¼°é£é™©ç­‰çº§å¹¶æ¨èå‘å¸ƒç­–ç•¥
"""
```

Claude Codeçš„æ™ºèƒ½åˆ†æè¿‡ç¨‹ï¼š

```python
# æ™ºèƒ½å‘å¸ƒå†³ç­–ç³»ç»Ÿ
class IntelligentReleaseDecisionSystem:
    """æ™ºèƒ½å‘å¸ƒå†³ç­–ç³»ç»Ÿ"""
    
    def __init__(self):
        self.risk_analyzer = RiskAnalyzer()
        self.strategy_recommender = StrategyRecommender()
        self.historical_analyzer = HistoricalAnalyzer()
        self.business_impact_assessor = BusinessImpactAssessor()
    
    async def analyze_release_readiness(self, change_context: Dict) -> Dict:
        """åˆ†æå‘å¸ƒå°±ç»ªæ€§"""
        
        print("ğŸ§  å¼€å§‹æ™ºèƒ½å‘å¸ƒåˆ†æ...")
        
        # 1. ä»£ç å˜æ›´åˆ†æ
        code_analysis = await self.analyze_code_changes(change_context)
        print(f"ğŸ“Š ä»£ç å˜æ›´åˆ†æå®Œæˆ:")
        print(f"  - å˜æ›´æ–‡ä»¶æ•°: {code_analysis['files_changed']}")
        print(f"  - ä»£ç è¡Œæ•°å˜æ›´: +{code_analysis['lines_added']} -{code_analysis['lines_removed']}")
        print(f"  - å¤æ‚åº¦å˜åŒ–: {code_analysis['complexity_change']}")
        
        # 2. é£é™©ç­‰çº§è¯„ä¼°
        risk_assessment = await self.risk_analyzer.assess_risk(change_context)
        print(f"âš ï¸ é£é™©è¯„ä¼°ç»“æœ:")
        print(f"  - æ€»ä½“é£é™©: {risk_assessment['overall_risk']}")
        print(f"  - å®‰å…¨é£é™©: {risk_assessment['security_risk']}")
        print(f"  - æ€§èƒ½é£é™©: {risk_assessment['performance_risk']}")
        print(f"  - å…¼å®¹æ€§é£é™©: {risk_assessment['compatibility_risk']}")
        
        # 3. å†å²æ•°æ®åˆ†æ
        historical_insights = await self.historical_analyzer.analyze_similar_releases(
            change_context
        )
        print(f"ğŸ“ˆ å†å²æ•°æ®æ´å¯Ÿ:")
        print(f"  - ç›¸ä¼¼å‘å¸ƒæˆåŠŸç‡: {historical_insights['success_rate']:.1%}")
        print(f"  - å¹³å‡å›æ»šç‡: {historical_insights['rollback_rate']:.1%}")
        print(f"  - ç”¨æˆ·å½±å“ç¨‹åº¦: {historical_insights['user_impact']}")
        
        # 4. ä¸šåŠ¡å½±å“è¯„ä¼°
        business_impact = await self.business_impact_assessor.assess_impact(
            change_context, risk_assessment
        )
        print(f"ğŸ’¼ ä¸šåŠ¡å½±å“è¯„ä¼°:")
        print(f"  - æ½œåœ¨æ”¶ç›Š: {business_impact['potential_benefits']}")
        print(f"  - é£é™©æˆæœ¬: {business_impact['risk_cost']}")
        print(f"  - ç´§æ€¥ç¨‹åº¦: {business_impact['urgency']}")
        
        # 5. å‘å¸ƒç­–ç•¥æ¨è
        strategy_recommendation = await self.strategy_recommender.recommend_strategy(
            code_analysis, risk_assessment, historical_insights, business_impact
        )
        
        print(f"ğŸ¯ å‘å¸ƒç­–ç•¥æ¨è:")
        print(f"  - æ¨èç­–ç•¥: {strategy_recommendation['strategy']}")
        print(f"  - å‘å¸ƒæ—¶æœº: {strategy_recommendation['timing']}")
        print(f"  - å‘å¸ƒèŒƒå›´: {strategy_recommendation['scope']}")
        print(f"  - ç›‘æ§é‡ç‚¹: {strategy_recommendation['monitoring_focus']}")
        
        return {
            "analysis_timestamp": datetime.now().isoformat(),
            "code_analysis": code_analysis,
            "risk_assessment": risk_assessment,
            "historical_insights": historical_insights,
            "business_impact": business_impact,
            "strategy_recommendation": strategy_recommendation,
            "confidence_score": strategy_recommendation['confidence']
        }
    
    async def analyze_code_changes(self, change_context: Dict) -> Dict:
        """åˆ†æä»£ç å˜æ›´"""
        
        changed_files = change_context.get('changed_files', [])
        commit_messages = change_context.get('commit_messages', [])
        
        analysis = {
            "files_changed": len(changed_files),
            "lines_added": 0,
            "lines_removed": 0,
            "complexity_change": "ä½",
            "critical_files_affected": [],
            "change_categories": [],
            "test_coverage_impact": "æ— å½±å“"
        }
        
        # åˆ†æå˜æ›´ç±»å‹
        change_categories = set()
        critical_files = []
        
        for file_path in changed_files:
            if any(keyword in file_path.lower() for keyword in ['auth', 'login', 'security']):
                critical_files.append(file_path)
                change_categories.add('security')
            elif any(keyword in file_path.lower() for keyword in ['database', 'query', 'sql']):
                change_categories.add('performance')
            elif any(keyword in file_path.lower() for keyword in ['api', 'endpoint']):
                change_categories.add('api_change')
            elif 'package.json' in file_path or 'requirements.txt' in file_path:
                change_categories.add('dependency_update')
        
        analysis["critical_files_affected"] = critical_files
        analysis["change_categories"] = list(change_categories)
        
        # æ ¹æ®å˜æ›´ç±»å‹è°ƒæ•´å¤æ‚åº¦è¯„ä¼°
        if 'security' in change_categories:
            analysis["complexity_change"] = "é«˜"
        elif len(change_categories) > 2:
            analysis["complexity_change"] = "ä¸­"
        
        return analysis

class RiskAnalyzer:
    """é£é™©åˆ†æå™¨"""
    
    async def assess_risk(self, change_context: Dict) -> Dict:
        """è¯„ä¼°å‘å¸ƒé£é™©"""
        
        risk_factors = {
            "security_risk": "ä½",
            "performance_risk": "ä½", 
            "compatibility_risk": "ä½",
            "operational_risk": "ä½",
            "overall_risk": "ä½"
        }
        
        changed_files = change_context.get('changed_files', [])
        change_categories = change_context.get('change_categories', [])
        
        # å®‰å…¨é£é™©è¯„ä¼°
        if 'security' in change_categories:
            risk_factors["security_risk"] = "ä¸­"
            if any('auth' in f.lower() for f in changed_files):
                risk_factors["security_risk"] = "é«˜"
        
        # æ€§èƒ½é£é™©è¯„ä¼°
        if 'performance' in change_categories:
            risk_factors["performance_risk"] = "ä¸­"
            if any('database' in f.lower() for f in changed_files):
                risk_factors["performance_risk"] = "é«˜"
        
        # å…¼å®¹æ€§é£é™©è¯„ä¼°
        if 'dependency_update' in change_categories:
            risk_factors["compatibility_risk"] = "ä¸­"
        if 'api_change' in change_categories:
            risk_factors["compatibility_risk"] = "é«˜"
        
        # è®¡ç®—æ€»ä½“é£é™©
        risk_levels = {"ä½": 1, "ä¸­": 2, "é«˜": 3}
        avg_risk = sum(risk_levels[risk] for risk in [
            risk_factors["security_risk"],
            risk_factors["performance_risk"], 
            risk_factors["compatibility_risk"],
            risk_factors["operational_risk"]
        ]) / 4
        
        if avg_risk >= 2.5:
            risk_factors["overall_risk"] = "é«˜"
        elif avg_risk >= 1.5:
            risk_factors["overall_risk"] = "ä¸­"
        
        return risk_factors

class StrategyRecommender:
    """ç­–ç•¥æ¨èå™¨"""
    
    async def recommend_strategy(self, code_analysis: Dict, risk_assessment: Dict, 
                               historical_insights: Dict, business_impact: Dict) -> Dict:
        """æ¨èå‘å¸ƒç­–ç•¥"""
        
        overall_risk = risk_assessment["overall_risk"]
        urgency = business_impact["urgency"]
        success_rate = historical_insights["success_rate"]
        
        # åŸºäºé£é™©å’Œç´§æ€¥ç¨‹åº¦é€‰æ‹©ç­–ç•¥
        if overall_risk == "é«˜":
            if urgency == "ç´§æ€¥":
                strategy = "canary"  # é‡‘ä¸é›€å‘å¸ƒï¼Œè°¨æ…æ¨è¿›
                scope = "limited"
            else:
                strategy = "blue-green"  # è“ç»¿å‘å¸ƒï¼Œå¯å¿«é€Ÿå›æ»š
                scope = "full"
        elif overall_risk == "ä¸­":
            if success_rate > 0.9:
                strategy = "rolling"  # æ»šåŠ¨å‘å¸ƒ
                scope = "full"
            else:
                strategy = "canary"
                scope = "gradual"
        else:  # ä½é£é™©
            strategy = "rolling"
            scope = "full"
        
        # å‘å¸ƒæ—¶æœºå»ºè®®
        if urgency == "ç´§æ€¥":
            timing = "immediate"
        elif overall_risk == "é«˜":
            timing = "off-peak-hours"
        else:
            timing = "business-hours"
        
        # ç›‘æ§é‡ç‚¹
        monitoring_focus = []
        if risk_assessment["security_risk"] in ["ä¸­", "é«˜"]:
            monitoring_focus.append("security_metrics")
        if risk_assessment["performance_risk"] in ["ä¸­", "é«˜"]:
            monitoring_focus.append("performance_metrics")
        if risk_assessment["compatibility_risk"] in ["ä¸­", "é«˜"]:
            monitoring_focus.append("error_rates")
        
        # ä¿¡å¿ƒåº¦è®¡ç®—
        confidence_factors = [
            success_rate,  # å†å²æˆåŠŸç‡
            1.0 if overall_risk == "ä½" else 0.7 if overall_risk == "ä¸­" else 0.4,  # é£é™©è°ƒæ•´
            1.0 if len(code_analysis["critical_files_affected"]) == 0 else 0.8  # å…³é”®æ–‡ä»¶å½±å“
        ]
        confidence = sum(confidence_factors) / len(confidence_factors)
        
        return {
            "strategy": strategy,
            "timing": timing,
            "scope": scope,
            "monitoring_focus": monitoring_focus,
            "confidence": confidence,
            "rationale": self._generate_rationale(
                strategy, overall_risk, urgency, success_rate
            )
        }
    
    def _generate_rationale(self, strategy: str, risk: str, urgency: str, success_rate: float) -> str:
        """ç”Ÿæˆæ¨èç†ç”±"""
        reasons = []
        
        if strategy == "canary":
            reasons.append(f"è€ƒè™‘åˆ°{risk}é£é™©ç­‰çº§ï¼Œå»ºè®®é‡‡ç”¨é‡‘ä¸é›€å‘å¸ƒé€æ­¥éªŒè¯")
        elif strategy == "blue-green":
            reasons.append(f"è“ç»¿å‘å¸ƒå¯ä»¥åœ¨{risk}é£é™©æƒ…å†µä¸‹å®ç°å¿«é€Ÿå›æ»š")
        elif strategy == "rolling":
            reasons.append(f"åŸºäº{success_rate:.1%}çš„å†å²æˆåŠŸç‡ï¼Œæ»šåŠ¨å‘å¸ƒæ˜¯æœ€ä¼˜é€‰æ‹©")
        
        if urgency == "ç´§æ€¥":
            reasons.append("ç´§æ€¥ç¨‹åº¦è¦æ±‚å¿«é€Ÿå‘å¸ƒ")
        
        return "ï¼›".join(reasons)

# ä½¿ç”¨ç¤ºä¾‹
async def demo_intelligent_release_decision():
    """æ¼”ç¤ºæ™ºèƒ½å‘å¸ƒå†³ç­–"""
    
    system = IntelligentReleaseDecisionSystem()
    
    # æ¨¡æ‹Ÿå˜æ›´ä¸Šä¸‹æ–‡
    change_context = {
        "changed_files": [
            "src/auth/login.py",
            "src/database/user_queries.sql", 
            "src/api/endpoints/user.py",
            "package.json"
        ],
        "commit_messages": [
            "fix: ä¿®å¤ç”¨æˆ·ç™»å½•å®‰å…¨æ¼æ´",
            "perf: ä¼˜åŒ–ç”¨æˆ·æŸ¥è¯¢æ€§èƒ½",
            "feat: æ·»åŠ æ–°çš„ç”¨æˆ·APIç«¯ç‚¹",
            "chore: æ›´æ–°ä¾èµ–åŒ…ç‰ˆæœ¬"
        ],
        "change_categories": ["security", "performance", "api_change", "dependency_update"],
        "branch": "main",
        "author": "dev-team"
    }
    
    # æ‰§è¡Œæ™ºèƒ½åˆ†æ
    result = await system.analyze_release_readiness(change_context)
    
    print(f"\nğŸ¯ æœ€ç»ˆå‘å¸ƒå»ºè®®:")
    print(f"  ç­–ç•¥: {result['strategy_recommendation']['strategy']}")
    print(f"  æ—¶æœº: {result['strategy_recommendation']['timing']}")
    print(f"  èŒƒå›´: {result['strategy_recommendation']['scope']}")
    print(f"  ä¿¡å¿ƒåº¦: {result['strategy_recommendation']['confidence']:.1%}")
    print(f"  ç†ç”±: {result['strategy_recommendation']['rationale']}")
    
    return result

# æ‰§è¡Œæ¼”ç¤º
await demo_intelligent_release_decision()
```

### åœºæ™¯2ï¼šè‡ªåŠ¨åŒ–å›æ»šå†³ç­–ç³»ç»Ÿ

```python
class AutomatedRollbackSystem:
    """è‡ªåŠ¨åŒ–å›æ»šå†³ç­–ç³»ç»Ÿ"""
    
    def __init__(self):
        self.monitoring_system = MonitoringSystem()
        self.decision_engine = RollbackDecisionEngine()
        self.rollback_executor = RollbackExecutor()
        
    async def monitor_deployment(self, deployment_id: str, duration_minutes: int = 30):
        """ç›‘æ§éƒ¨ç½²çŠ¶æ€å¹¶è‡ªåŠ¨å†³ç­–å›æ»š"""
        
        print(f"ğŸ“Š å¼€å§‹ç›‘æ§éƒ¨ç½² {deployment_id}ï¼ŒæŒç»­ {duration_minutes} åˆ†é’Ÿ")
        
        start_time = datetime.now()
        end_time = start_time + timedelta(minutes=duration_minutes)
        
        while datetime.now() < end_time:
            # æ”¶é›†ç›‘æ§æ•°æ®
            metrics = await self.monitoring_system.collect_metrics(deployment_id)
            
            # åˆ†ææ˜¯å¦éœ€è¦å›æ»š
            rollback_decision = await self.decision_engine.should_rollback(
                metrics, deployment_id
            )
            
            if rollback_decision['should_rollback']:
                print(f"ğŸš¨ æ£€æµ‹åˆ°ä¸¥é‡é—®é¢˜ï¼Œè§¦å‘è‡ªåŠ¨å›æ»š:")
                print(f"  è§¦å‘åŸå› : {rollback_decision['reasons']}")
                print(f"  ä¸¥é‡ç¨‹åº¦: {rollback_decision['severity']}")
                
                # æ‰§è¡Œè‡ªåŠ¨å›æ»š
                rollback_result = await self.rollback_executor.execute_rollback(
                    deployment_id, rollback_decision
                )
                
                if rollback_result['success']:
                    print(f"âœ… è‡ªåŠ¨å›æ»šæˆåŠŸ:")
                    print(f"  å›æ»šæ—¶é—´: {rollback_result['duration']}")
                    print(f"  æ¢å¤çŠ¶æ€: {rollback_result['health_status']}")
                    
                    # å‘é€é€šçŸ¥
                    await self.send_rollback_notification(
                        deployment_id, rollback_decision, rollback_result
                    )
                    
                    return rollback_result
                else:
                    print(f"âŒ è‡ªåŠ¨å›æ»šå¤±è´¥ï¼Œéœ€è¦äººå·¥ä»‹å…¥:")
                    print(f"  å¤±è´¥åŸå› : {rollback_result['error']}")
                    
                    # å‘é€ç´§æ€¥é€šçŸ¥
                    await self.send_emergency_notification(
                        deployment_id, rollback_result
                    )
                    
                    return rollback_result
            
            # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
            await asyncio.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
        
        print(f"âœ… éƒ¨ç½²ç›‘æ§å®Œæˆï¼Œæœªå‘ç°éœ€è¦å›æ»šçš„é—®é¢˜")
        return {"success": True, "action": "monitoring_completed"}
    
    async def send_rollback_notification(self, deployment_id: str, 
                                       decision: Dict, result: Dict):
        """å‘é€å›æ»šé€šçŸ¥"""
        
        message = f"""
ğŸš¨ **è‡ªåŠ¨å›æ»šæ‰§è¡Œé€šçŸ¥**

**éƒ¨ç½²ID**: {deployment_id}
**è§¦å‘æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**è§¦å‘åŸå› **: {', '.join(decision['reasons'])}
**ä¸¥é‡ç¨‹åº¦**: {decision['severity']}

**å›æ»šç»“æœ**:
- æ‰§è¡ŒçŠ¶æ€: {'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}
- è€—æ—¶: {result['duration']}
- ç³»ç»ŸçŠ¶æ€: {result['health_status']}

**åç»­è¡ŒåŠ¨**:
1. è°ƒæŸ¥é—®é¢˜æ ¹å› 
2. ä¿®å¤ç›¸å…³é—®é¢˜
3. é‡æ–°éƒ¨ç½²ä¿®å¤ç‰ˆæœ¬

*æ­¤é€šçŸ¥ç”± Claude Code è‡ªåŠ¨å›æ»šç³»ç»Ÿç”Ÿæˆ*
        """
        
        # å‘é€åˆ° Slack
        await self.send_slack_notification(
            channel="#deployments",
            message=message,
            severity="warning"
        )
        
        # å‘é€é‚®ä»¶ç»™å…³é”®äººå‘˜
        await self.send_email_notification(
            recipients=["devops@company.com", "oncall@company.com"],
            subject=f"è‡ªåŠ¨å›æ»šæ‰§è¡Œ - {deployment_id}",
            body=message
        )

class RollbackDecisionEngine:
    """å›æ»šå†³ç­–å¼•æ“"""
    
    def __init__(self):
        self.thresholds = {
            "error_rate": 5.0,      # é”™è¯¯ç‡ > 5%
            "response_time_p95": 5000,  # P95å“åº”æ—¶é—´ > 5ç§’
            "availability": 95.0,    # å¯ç”¨æ€§ < 95%
            "memory_usage": 90.0,    # å†…å­˜ä½¿ç”¨ç‡ > 90%
            "cpu_usage": 85.0        # CPUä½¿ç”¨ç‡ > 85%
        }
    
    async def should_rollback(self, metrics: Dict, deployment_id: str) -> Dict:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å›æ»š"""
        
        violations = []
        severity_scores = []
        
        # æ£€æŸ¥å„é¡¹æŒ‡æ ‡
        for metric, threshold in self.thresholds.items():
            if metric in metrics:
                value = metrics[metric]
                
                if metric == "availability" and value < threshold:
                    violations.append(f"å¯ç”¨æ€§ {value:.1f}% < {threshold}%")
                    severity_scores.append(10)  # æœ€é«˜ä¸¥é‡ç¨‹åº¦
                    
                elif metric == "error_rate" and value > threshold:
                    violations.append(f"é”™è¯¯ç‡ {value:.1f}% > {threshold}%")
                    severity_scores.append(8)
                    
                elif metric == "response_time_p95" and value > threshold:
                    violations.append(f"P95å“åº”æ—¶é—´ {value}ms > {threshold}ms")
                    severity_scores.append(6)
                    
                elif metric in ["memory_usage", "cpu_usage"] and value > threshold:
                    violations.append(f"{metric} {value:.1f}% > {threshold}%")
                    severity_scores.append(4)
        
        # å†³ç­–é€»è¾‘
        should_rollback = False
        severity = "low"
        
        if violations:
            max_severity = max(severity_scores) if severity_scores else 0
            
            if max_severity >= 8:
                should_rollback = True
                severity = "critical"
            elif max_severity >= 6 and len(violations) >= 2:
                should_rollback = True
                severity = "high"
            elif len(violations) >= 3:
                should_rollback = True
                severity = "medium"
        
        return {
            "should_rollback": should_rollback,
            "reasons": violations,
            "severity": severity,
            "confidence": self._calculate_confidence(violations, metrics),
            "timestamp": datetime.now().isoformat()
        }
    
    def _calculate_confidence(self, violations: List[str], metrics: Dict) -> float:
        """è®¡ç®—å†³ç­–ä¿¡å¿ƒåº¦"""
        
        if not violations:
            return 1.0
        
        # åŸºäºæ•°æ®å®Œæ•´æ€§å’Œé˜ˆå€¼è¶…å‡ºç¨‹åº¦è®¡ç®—ä¿¡å¿ƒåº¦
        data_completeness = len(metrics) / len(self.thresholds)
        violation_severity = len(violations) / len(self.thresholds)
        
        confidence = (data_completeness + violation_severity) / 2
        return min(confidence, 1.0)

# ä½¿ç”¨ç¤ºä¾‹
rollback_system = AutomatedRollbackSystem()

# å¯åŠ¨éƒ¨ç½²ç›‘æ§
await rollback_system.monitor_deployment(
    deployment_id="deploy-20240817-001",
    duration_minutes=60  # ç›‘æ§1å°æ—¶
)
```

### åœºæ™¯3ï¼šæ™ºèƒ½æ€§èƒ½æµ‹è¯•è°ƒåº¦

```python
class IntelligentPerformanceTestScheduler:
    """æ™ºèƒ½æ€§èƒ½æµ‹è¯•è°ƒåº¦å™¨"""
    
    def __init__(self):
        self.workload_analyzer = WorkloadAnalyzer()
        self.test_optimizer = TestOptimizer()
        self.resource_manager = ResourceManager()
    
    async def schedule_performance_tests(self, deployment_context: Dict) -> Dict:
        """æ™ºèƒ½è°ƒåº¦æ€§èƒ½æµ‹è¯•"""
        
        print("âš¡ å¼€å§‹æ™ºèƒ½æ€§èƒ½æµ‹è¯•è°ƒåº¦...")
        
        # 1. åˆ†æåº”ç”¨å·¥ä½œè´Ÿè½½ç‰¹å¾
        workload_profile = await self.workload_analyzer.analyze_workload(
            deployment_context
        )
        
        print(f"ğŸ“Š å·¥ä½œè´Ÿè½½åˆ†æ:")
        print(f"  åº”ç”¨ç±»å‹: {workload_profile['app_type']}")
        print(f"  ä¸»è¦ç“¶é¢ˆ: {workload_profile['primary_bottleneck']}")
        print(f"  å¹¶å‘æ¨¡å¼: {workload_profile['concurrency_pattern']}")
        
        # 2. ä¼˜åŒ–æµ‹è¯•ç­–ç•¥
        test_strategy = await self.test_optimizer.optimize_test_strategy(
            workload_profile, deployment_context
        )
        
        print(f"ğŸ¯ æµ‹è¯•ç­–ç•¥ä¼˜åŒ–:")
        print(f"  æµ‹è¯•ç±»å‹: {test_strategy['test_types']}")
        print(f"  è´Ÿè½½æ¨¡å¼: {test_strategy['load_patterns']}")
        print(f"  å…³é”®æŒ‡æ ‡: {test_strategy['key_metrics']}")
        
        # 3. èµ„æºåˆ†é…å’Œè°ƒåº¦
        resource_allocation = await self.resource_manager.allocate_resources(
            test_strategy
        )
        
        print(f"ğŸ”§ èµ„æºåˆ†é…:")
        print(f"  æµ‹è¯•ç¯å¢ƒ: {resource_allocation['test_environment']}")
        print(f"  è´Ÿè½½ç”Ÿæˆå™¨: {resource_allocation['load_generators']}")
        print(f"  ç›‘æ§å·¥å…·: {resource_allocation['monitoring_tools']}")
        
        # 4. æ‰§è¡Œæ€§èƒ½æµ‹è¯•
        test_results = await self.execute_performance_tests(
            test_strategy, resource_allocation
        )
        
        # 5. åˆ†æç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š
        analysis_report = await self.analyze_test_results(
            test_results, workload_profile
        )
        
        return {
            "workload_profile": workload_profile,
            "test_strategy": test_strategy,
            "resource_allocation": resource_allocation,
            "test_results": test_results,
            "analysis_report": analysis_report
        }
    
    async def execute_performance_tests(self, strategy: Dict, resources: Dict) -> Dict:
        """æ‰§è¡Œæ€§èƒ½æµ‹è¯•"""
        
        results = {}
        
        for test_type in strategy['test_types']:
            print(f"ğŸ§ª æ‰§è¡Œ {test_type} æ€§èƒ½æµ‹è¯•...")
            
            if test_type == "load_test":
                results[test_type] = await self.run_load_test(strategy, resources)
            elif test_type == "stress_test":
                results[test_type] = await self.run_stress_test(strategy, resources)
            elif test_type == "spike_test":
                results[test_type] = await self.run_spike_test(strategy, resources)
            elif test_type == "volume_test":
                results[test_type] = await self.run_volume_test(strategy, resources)
            elif test_type == "endurance_test":
                results[test_type] = await self.run_endurance_test(strategy, resources)
        
        return results
    
    async def run_load_test(self, strategy: Dict, resources: Dict) -> Dict:
        """è¿è¡Œè´Ÿè½½æµ‹è¯•"""
        
        print("  ğŸ“ˆ æ‰§è¡Œè´Ÿè½½æµ‹è¯•...")
        
        test_config = {
            "duration": "10m",
            "virtual_users": 100,
            "ramp_up_time": "2m",
            "target_rps": strategy.get('target_rps', 1000),
            "scenarios": [
                {
                    "name": "user_journey_1", 
                    "weight": 70,
                    "steps": ["login", "browse", "search", "logout"]
                },
                {
                    "name": "user_journey_2",
                    "weight": 30, 
                    "steps": ["login", "purchase", "logout"]
                }
            ]
        }
        
        # æ¨¡æ‹Ÿæµ‹è¯•æ‰§è¡Œ
        await asyncio.sleep(2)  # æ¨¡æ‹Ÿæµ‹è¯•æ—¶é—´
        
        return {
            "test_type": "load_test",
            "duration": "10m",
            "average_response_time": 250,  # ms
            "p95_response_time": 800,      # ms
            "p99_response_time": 1200,     # ms
            "throughput": 950,             # rps
            "error_rate": 0.5,             # %
            "concurrent_users": 100,
            "passed": True,
            "performance_budget_met": True
        }
    
    async def run_stress_test(self, strategy: Dict, resources: Dict) -> Dict:
        """è¿è¡Œå‹åŠ›æµ‹è¯•"""
        
        print("  ğŸ’ª æ‰§è¡Œå‹åŠ›æµ‹è¯•...")
        
        # æ¨¡æ‹Ÿå‹åŠ›æµ‹è¯•æ‰§è¡Œ
        await asyncio.sleep(3)
        
        return {
            "test_type": "stress_test",
            "duration": "15m",
            "peak_users": 500,
            "breaking_point": 450,         # ç³»ç»Ÿå¼€å§‹ä¸ç¨³å®šçš„ç”¨æˆ·æ•°
            "max_throughput": 2100,        # rps
            "recovery_time": 30,           # ç§’ï¼Œç³»ç»Ÿæ¢å¤æ—¶é—´
            "resource_utilization": {
                "cpu": 85,                 # %
                "memory": 78,              # %
                "disk_io": 60             # %
            },
            "passed": True
        }
    
    async def analyze_test_results(self, results: Dict, workload_profile: Dict) -> Dict:
        """åˆ†ææµ‹è¯•ç»“æœ"""
        
        print("ğŸ“Š åˆ†ææ€§èƒ½æµ‹è¯•ç»“æœ...")
        
        analysis = {
            "overall_performance": "è‰¯å¥½",
            "bottlenecks": [],
            "recommendations": [],
            "pass_criteria_met": True,
            "performance_trends": {},
            "risk_assessment": "ä½é£é™©"
        }
        
        # åˆ†æå„é¡¹æµ‹è¯•ç»“æœ
        for test_type, result in results.items():
            if test_type == "load_test":
                if result['p95_response_time'] > 1000:
                    analysis["bottlenecks"].append("å“åº”æ—¶é—´åæ…¢")
                    analysis["recommendations"].append("ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æˆ–å¢åŠ ç¼“å­˜")
                
                if result['error_rate'] > 1.0:
                    analysis["bottlenecks"].append("é”™è¯¯ç‡åé«˜")
                    analysis["recommendations"].append("æ£€æŸ¥é”™è¯¯å¤„ç†é€»è¾‘")
            
            elif test_type == "stress_test":
                cpu_usage = result['resource_utilization']['cpu']
                if cpu_usage > 80:
                    analysis["bottlenecks"].append("CPUä½¿ç”¨ç‡è¿‡é«˜")
                    analysis["recommendations"].append("è€ƒè™‘æ°´å¹³æ‰©å±•æˆ–CPUä¼˜åŒ–")
        
        # æ€»ä½“é£é™©è¯„ä¼°
        if analysis["bottlenecks"]:
            analysis["risk_assessment"] = "ä¸­é£é™©" if len(analysis["bottlenecks"]) > 2 else "ä½é£é™©"
            analysis["overall_performance"] = "éœ€è¦ä¼˜åŒ–"
        
        return analysis

# ä½¿ç”¨ç¤ºä¾‹
scheduler = IntelligentPerformanceTestScheduler()

deployment_context = {
    "application_type": "web_api",
    "expected_load": "high",
    "critical_endpoints": ["/api/users", "/api/orders"],
    "deployment_environment": "staging",
    "previous_performance_baseline": {
        "avg_response_time": 200,
        "p95_response_time": 500,
        "throughput": 1000
    }
}

test_results = await scheduler.schedule_performance_tests(deployment_context)
print(f"\nğŸ¯ æ€§èƒ½æµ‹è¯•å®Œæˆ:")
print(f"  æ€»ä½“æ€§èƒ½: {test_results['analysis_report']['overall_performance']}")
print(f"  é£é™©è¯„ä¼°: {test_results['analysis_report']['risk_assessment']}")
print(f"  æ”¹è¿›å»ºè®®: {test_results['analysis_report']['recommendations']}")
```

## é«˜çº§CI/CDä¼˜åŒ–ç­–ç•¥

### 1. æ™ºèƒ½æµ‹è¯•é€‰æ‹©å’Œä¼˜åŒ–

#### åŸºäºAIçš„æµ‹è¯•ç­–ç•¥ä¼˜åŒ–

```python
class IntelligentTestStrategy:
    """æ™ºèƒ½æµ‹è¯•ç­–ç•¥ç³»ç»Ÿ"""
    
    def __init__(self):
        self.test_analyzer = TestAnalyzer()
        self.risk_calculator = RiskCalculator()
        self.optimization_engine = OptimizationEngine()
    
    async def optimize_test_execution(self, change_context: Dict) -> Dict:
        """ä¼˜åŒ–æµ‹è¯•æ‰§è¡Œç­–ç•¥"""
        
        print("ğŸ§ª å¼€å§‹æ™ºèƒ½æµ‹è¯•ç­–ç•¥ä¼˜åŒ–...")
        
        # 1. åˆ†æä»£ç å˜æ›´å½±å“
        impact_analysis = await self.analyze_change_impact(change_context)
        
        # 2. è®¡ç®—æµ‹è¯•é£é™©å’Œä¼˜å…ˆçº§
        test_priorities = await self.calculate_test_priorities(
            impact_analysis, change_context
        )
        
        # 3. ä¼˜åŒ–æµ‹è¯•é€‰æ‹©
        optimized_test_plan = await self.optimize_test_selection(
            test_priorities, change_context
        )
        
        # 4. ç”Ÿæˆå¹¶è¡Œæ‰§è¡Œè®¡åˆ’
        execution_plan = await self.generate_execution_plan(
            optimized_test_plan
        )
        
        return {
            "impact_analysis": impact_analysis,
            "test_priorities": test_priorities,
            "optimized_plan": optimized_test_plan,
            "execution_plan": execution_plan,
            "estimated_time_saved": execution_plan['time_savings'],
            "confidence_score": execution_plan['confidence']
        }
    
    async def analyze_change_impact(self, change_context: Dict) -> Dict:
        """åˆ†æä»£ç å˜æ›´çš„å½±å“èŒƒå›´"""
        
        changed_files = change_context.get('changed_files', [])
        
        impact_analysis = {
            "affected_modules": [],
            "affected_features": [],
            "test_categories_needed": [],
            "critical_path_affected": False,
            "database_changes": False,
            "api_changes": False,
            "ui_changes": False
        }
        
        for file_path in changed_files:
            # æ¨¡å—å½±å“åˆ†æ
            if 'models/' in file_path or 'database/' in file_path:
                impact_analysis["affected_modules"].append("data_layer")
                impact_analysis["database_changes"] = True
                impact_analysis["test_categories_needed"].append("integration_test")
                
            elif 'api/' in file_path or 'controllers/' in file_path:
                impact_analysis["affected_modules"].append("api_layer")
                impact_analysis["api_changes"] = True
                impact_analysis["test_categories_needed"].extend(["unit_test", "api_test"])
                
            elif 'frontend/' in file_path or 'components/' in file_path:
                impact_analysis["affected_modules"].append("ui_layer")
                impact_analysis["ui_changes"] = True
                impact_analysis["test_categories_needed"].extend(["unit_test", "e2e_test"])
        
        # å»é‡
        impact_analysis["test_categories_needed"] = list(set(impact_analysis["test_categories_needed"]))
        impact_analysis["affected_modules"] = list(set(impact_analysis["affected_modules"]))
        
        return impact_analysis
    
    async def calculate_test_priorities(self, impact_analysis: Dict, 
                                      change_context: Dict) -> Dict:
        """è®¡ç®—æµ‹è¯•ä¼˜å…ˆçº§"""
        
        test_priorities = {
            "critical": [],    # å¿…é¡»æ‰§è¡Œçš„æµ‹è¯•
            "high": [],        # é«˜ä¼˜å…ˆçº§æµ‹è¯•
            "medium": [],      # ä¸­ä¼˜å…ˆçº§æµ‹è¯•
            "low": []          # ä½ä¼˜å…ˆçº§æµ‹è¯•
        }
        
        # åŸºäºå½±å“åˆ†æåˆ†é…ä¼˜å…ˆçº§
        if impact_analysis["database_changes"]:
            test_priorities["critical"].extend([
                "database_migration_tests",
                "data_integrity_tests"
            ])
            test_priorities["high"].append("integration_tests")
        
        if impact_analysis["api_changes"]:
            test_priorities["critical"].append("api_contract_tests")
            test_priorities["high"].append("api_integration_tests")
        
        if impact_analysis["ui_changes"]:
            test_priorities["high"].append("ui_component_tests")
            test_priorities["medium"].append("visual_regression_tests")
        
        # åŸºäºå†å²å¤±è´¥ç‡è°ƒæ•´ä¼˜å…ˆçº§
        historical_data = change_context.get('historical_test_data', {})
        for test_name, failure_rate in historical_data.items():
            if failure_rate > 0.1:  # å¤±è´¥ç‡è¶…è¿‡10%
                if test_name in test_priorities["medium"]:
                    test_priorities["medium"].remove(test_name)
                    test_priorities["high"].append(test_name)
                elif test_name in test_priorities["low"]:
                    test_priorities["low"].remove(test_name)
                    test_priorities["medium"].append(test_name)
        
        return test_priorities
    
    async def optimize_test_selection(self, test_priorities: Dict, 
                                    change_context: Dict) -> Dict:
        """ä¼˜åŒ–æµ‹è¯•é€‰æ‹©"""
        
        time_budget = change_context.get('time_budget_minutes', 30)
        
        selected_tests = {
            "unit_tests": [],
            "integration_tests": [],
            "e2e_tests": [],
            "performance_tests": [],
            "security_tests": []
        }
        
        # é¢„ä¼°å„ç±»æµ‹è¯•æ—¶é—´
        test_time_estimates = {
            "unit_tests": 5,           # 5åˆ†é’Ÿ
            "integration_tests": 10,   # 10åˆ†é’Ÿ
            "e2e_tests": 15,          # 15åˆ†é’Ÿ
            "performance_tests": 20,   # 20åˆ†é’Ÿ
            "security_tests": 10       # 10åˆ†é’Ÿ
        }
        
        remaining_time = time_budget
        
        # æŒ‰ä¼˜å…ˆçº§é€‰æ‹©æµ‹è¯•
        for priority in ["critical", "high", "medium", "low"]:
            for test_category in test_priorities[priority]:
                estimated_time = test_time_estimates.get(test_category, 10)
                
                if remaining_time >= estimated_time:
                    if test_category not in selected_tests:
                        selected_tests[test_category] = []
                    selected_tests[test_category].append(priority)
                    remaining_time -= estimated_time
                    
                if remaining_time <= 0:
                    break
            
            if remaining_time <= 0:
                break
        
        return {
            "selected_tests": selected_tests,
            "total_estimated_time": time_budget - remaining_time,
            "time_savings": remaining_time,
            "coverage_percentage": self._calculate_coverage(selected_tests, test_priorities)
        }
    
    def _calculate_coverage(self, selected_tests: Dict, all_priorities: Dict) -> float:
        """è®¡ç®—æµ‹è¯•è¦†ç›–ç‡"""
        
        total_tests = sum(len(tests) for tests in all_priorities.values())
        selected_count = sum(len(tests) for tests in selected_tests.values())
        
        return (selected_count / total_tests) * 100 if total_tests > 0 else 0

# ä½¿ç”¨ç¤ºä¾‹
test_strategy = IntelligentTestStrategy()

change_context = {
    "changed_files": [
        "src/models/user.py",
        "src/api/auth.py", 
        "src/frontend/components/LoginForm.vue"
    ],
    "time_budget_minutes": 25,
    "historical_test_data": {
        "auth_integration_tests": 0.15,  # 15%å¤±è´¥ç‡
        "login_e2e_tests": 0.05         # 5%å¤±è´¥ç‡
    }
}

optimization_result = await test_strategy.optimize_test_execution(change_context)

print(f"ğŸ¯ æ™ºèƒ½æµ‹è¯•ç­–ç•¥ç»“æœ:")
print(f"  é€‰å®šæµ‹è¯•: {optimization_result['optimized_plan']['selected_tests']}")
print(f"  é¢„è®¡è€—æ—¶: {optimization_result['optimized_plan']['total_estimated_time']} åˆ†é’Ÿ")
print(f"  èŠ‚çœæ—¶é—´: {optimization_result['optimized_plan']['time_savings']} åˆ†é’Ÿ")
print(f"  æµ‹è¯•è¦†ç›–: {optimization_result['optimized_plan']['coverage_percentage']:.1f}%")
```

### 2. æ™ºèƒ½èµ„æºè°ƒåº¦ç³»ç»Ÿ

#### åŠ¨æ€èµ„æºåˆ†é…ä¼˜åŒ–

```yaml
# .claude/config/intelligent-resource-scheduler.yml
resource_scheduler:
  
  # èµ„æºæ± é…ç½®
  resource_pools:
    # æ„å»ºèµ„æºæ± 
    build_pool:
      type: "compute"
      capacity:
        cpu_cores: 32
        memory: "64GB"
        storage: "1TB"
      instances:
        - name: "builder-1"
          cpu: 8
          memory: "16GB"
          specialization: ["java", "node", "python"]
        - name: "builder-2"
          cpu: 8
          memory: "16GB"
          specialization: ["go", "rust", "cpp"]
        - name: "builder-3"
          cpu: 16
          memory: "32GB"
          specialization: ["docker", "kubernetes"]
    
    # æµ‹è¯•èµ„æºæ± 
    test_pool:
      type: "compute"
      capacity:
        cpu_cores: 48
        memory: "96GB"
        storage: "2TB"
      instances:
        - name: "tester-1"
          cpu: 8
          memory: "16GB"
          specialization: ["unit_tests", "integration_tests"]
        - name: "tester-2"
          cpu: 12
          memory: "24GB"
          specialization: ["e2e_tests", "ui_tests"]
        - name: "tester-3"
          cpu: 16
          memory: "32GB"
          specialization: ["performance_tests", "load_tests"]
        - name: "tester-4"
          cpu: 12
          memory: "24GB"
          specialization: ["security_tests", "penetration_tests"]
    
    # éƒ¨ç½²èµ„æºæ± 
    deploy_pool:
      type: "compute"
      capacity:
        cpu_cores: 24
        memory: "48GB"
        storage: "500GB"
      instances:
        - name: "deployer-1"
          cpu: 8
          memory: "16GB"
          specialization: ["staging_deploy"]
        - name: "deployer-2"
          cpu: 16
          memory: "32GB"
          specialization: ["production_deploy", "rollback"]

  # æ™ºèƒ½è°ƒåº¦ç­–ç•¥
  scheduling_strategy:
    
    # è´Ÿè½½å‡è¡¡ç®—æ³•
    load_balancing:
      algorithm: "weighted_round_robin"  # round_robin | least_connections | weighted_round_robin
      weights:
        cpu_weight: 0.4
        memory_weight: 0.3
        specialization_weight: 0.3
    
    # èµ„æºé¢„æµ‹
    resource_prediction:
      enabled: true
      prediction_window: "2h"           # 2å°æ—¶é¢„æµ‹çª—å£
      
      # å†å²æ•°æ®åˆ†æ
      historical_analysis:
        data_retention: "30d"           # ä¿ç•™30å¤©æ•°æ®
        learning_window: "7d"           # 7å¤©å­¦ä¹ çª—å£
        trend_detection: true
        
      # é¢„æµ‹æ¨¡å‹
      prediction_models:
        - type: "time_series"
          algorithm: "arima"
          accuracy_threshold: 0.85
          
        - type: "machine_learning"
          algorithm: "random_forest"
          features: ["time_of_day", "day_of_week", "project_type", "team_size"]
    
    # åŠ¨æ€æ‰©ç¼©å®¹
    auto_scaling:
      enabled: true
      
      # æ‰©å®¹æ¡ä»¶
      scale_out_conditions:
        - metric: "cpu_utilization"
          threshold: 80
          duration: "5m"
          
        - metric: "queue_length" 
          threshold: 10
          duration: "2m"
          
        - metric: "wait_time"
          threshold: "300s"
          duration: "1m"
      
      # ç¼©å®¹æ¡ä»¶
      scale_in_conditions:
        - metric: "cpu_utilization"
          threshold: 20
          duration: "15m"
          
        - metric: "queue_length"
          threshold: 0
          duration: "10m"
      
      # æ‰©ç¼©å®¹ç­–ç•¥
      scaling_policy:
        min_instances: 1
        max_instances: 10
        scale_out_step: 2              # æ¯æ¬¡æ‰©å®¹2ä¸ªå®ä¾‹
        scale_in_step: 1               # æ¯æ¬¡ç¼©å®¹1ä¸ªå®ä¾‹
        cooldown_period: "300s"        # å†·å´æœŸ5åˆ†é’Ÿ

  # ä»»åŠ¡ä¼˜å…ˆçº§å’Œé˜Ÿåˆ—ç®¡ç†
  task_queue_management:
    
    # ä¼˜å…ˆçº§é˜Ÿåˆ—
    priority_queues:
      - name: "critical"
        priority: 100
        sla: "2m"                      # 2åˆ†é’Ÿå†…å¼€å§‹æ‰§è¡Œ
        resource_guarantee: 0.5        # ä¿è¯50%èµ„æº
        
      - name: "high"
        priority: 80
        sla: "5m"
        resource_guarantee: 0.3
        
      - name: "normal"
        priority: 50
        sla: "10m"
        resource_guarantee: 0.15
        
      - name: "low"
        priority: 20
        sla: "30m"
        resource_guarantee: 0.05
    
    # é˜Ÿåˆ—è°ƒåº¦ç®—æ³•
    queue_scheduling:
      algorithm: "priority_based_fair_queuing"
      
      # å…¬å¹³æ€§ä¿è¯
      fairness_constraints:
        max_wait_time_ratio: 3.0       # æœ€å¤§ç­‰å¾…æ—¶é—´æ¯”ä¾‹
        starvation_prevention: true    # é˜²æ­¢é¥¥é¥¿
        aging_factor: 0.1              # è€åŒ–å› å­
    
    # ä»»åŠ¡é¢„å¤„ç†
    task_preprocessing:
      enabled: true
      
      # ä»»åŠ¡åˆ†æ
      task_analysis:
        complexity_estimation: true
        resource_requirement_prediction: true
        execution_time_estimation: true
        
      # ä»»åŠ¡ä¼˜åŒ–
      task_optimization:
        dependency_analysis: true
        parallel_execution_planning: true
        resource_sharing_optimization: true

  # æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–
  performance_monitoring:
    
    # å®æ—¶ç›‘æ§æŒ‡æ ‡
    metrics:
      - name: "resource_utilization"
        collection_interval: "30s"
        
      - name: "task_completion_rate"
        collection_interval: "1m"
        
      - name: "queue_wait_time"
        collection_interval: "30s"
        
      - name: "sla_compliance"
        collection_interval: "5m"
    
    # æ€§èƒ½åŸºå‡†
    performance_baselines:
      task_completion_time:
        build_tasks: "300s"            # 5åˆ†é’Ÿ
        test_tasks: "600s"             # 10åˆ†é’Ÿ
        deploy_tasks: "180s"           # 3åˆ†é’Ÿ
        
      resource_efficiency:
        min_utilization: 60            # æœ€ä½60%åˆ©ç”¨ç‡
        max_utilization: 85            # æœ€é«˜85%åˆ©ç”¨ç‡
        
      sla_compliance:
        target: 95                     # 95% SLAè¾¾æ ‡ç‡
    
    # è‡ªåŠ¨ä¼˜åŒ–
    auto_optimization:
      enabled: true
      optimization_interval: "1h"     # æ¯å°æ—¶ä¼˜åŒ–ä¸€æ¬¡
      
      # ä¼˜åŒ–ç­–ç•¥
      optimization_strategies:
        - name: "resource_rebalancing"
          trigger: "utilization_imbalance > 30%"
          action: "redistribute_tasks"
          
        - name: "queue_optimization"
          trigger: "avg_wait_time > sla * 1.5"
          action: "adjust_priority_weights"
          
        - name: "capacity_adjustment"
          trigger: "sustained_high_utilization"
          action: "request_additional_resources"

# æ™ºèƒ½è°ƒåº¦ç®—æ³•é…ç½®
intelligent_scheduling:
  
  # AIè°ƒåº¦å¼•æ“
  ai_scheduler:
    enabled: true
    
    # æœºå™¨å­¦ä¹ æ¨¡å‹
    ml_models:
      - name: "resource_demand_predictor"
        type: "regression"
        algorithm: "gradient_boosting"
        features:
          - "historical_usage_patterns"
          - "team_activity_cycles"
          - "project_deadlines"
          - "seasonal_factors"
        retrain_interval: "daily"
        
      - name: "task_duration_predictor"
        type: "regression"
        algorithm: "neural_network"
        features:
          - "code_change_size"
          - "test_complexity"
          - "historical_execution_times"
          - "resource_allocation"
        retrain_interval: "weekly"
        
      - name: "optimal_resource_allocator"
        type: "optimization"
        algorithm: "genetic_algorithm"
        objective: "minimize_total_cost_while_meeting_sla"
        constraints:
          - "resource_capacity_limits"
          - "sla_requirements"
          - "fairness_constraints"
    
    # å†³ç­–æ”¯æŒç³»ç»Ÿ
    decision_support:
      # å¤šç›®æ ‡ä¼˜åŒ–
      multi_objective_optimization:
        objectives:
          - name: "minimize_cost"
            weight: 0.4
            
          - name: "maximize_throughput"
            weight: 0.3
            
          - name: "minimize_latency"
            weight: 0.2
            
          - name: "ensure_fairness"
            weight: 0.1
      
      # çº¦æŸæ¡ä»¶
      constraints:
        hard_constraints:
          - "sla_requirements_must_be_met"
          - "resource_capacity_cannot_be_exceeded"
          - "security_policies_must_be_enforced"
          
        soft_constraints:
          - "prefer_specialized_resources"
          - "minimize_context_switching"
          - "balance_team_resource_usage"

# æˆæœ¬ä¼˜åŒ–é…ç½®
cost_optimization:
  
  # æˆæœ¬æ¨¡å‹
  cost_model:
    # èµ„æºæˆæœ¬
    resource_costs:
      cpu_hour: 0.1                    # $0.1 per CPU hour
      memory_gb_hour: 0.02             # $0.02 per GB memory hour
      storage_gb_hour: 0.001           # $0.001 per GB storage hour
      network_gb: 0.01                 # $0.01 per GB network transfer
    
    # è¿è¥æˆæœ¬
    operational_costs:
      maintenance_overhead: 0.15       # 15% overhead
      support_cost_per_user: 10        # $10 per user per month
      infrastructure_management: 100   # $100 per month base cost
  
  # æˆæœ¬ä¼˜åŒ–ç­–ç•¥
  optimization_strategies:
    # èµ„æºä½¿ç”¨ä¼˜åŒ–
    resource_optimization:
      enabled: true
      
      strategies:
        - name: "idle_resource_reclamation"
          description: "å›æ”¶ç©ºé—²èµ„æº"
          idle_threshold: "10m"
          
        - name: "resource_consolidation"
          description: "èµ„æºæ•´åˆ"
          consolidation_threshold: 0.6  # 60%åˆ©ç”¨ç‡ä»¥ä¸‹è€ƒè™‘æ•´åˆ
          
        - name: "peak_shaving"
          description: "å‰Šå³°å¡«è°·"
          off_peak_discount: 0.3        # éé«˜å³°æ—¶æ®µ30%æŠ˜æ‰£
    
    # è°ƒåº¦ä¼˜åŒ–
    scheduling_optimization:
      enabled: true
      
      strategies:
        - name: "batch_processing"
          description: "æ‰¹å¤„ç†ä¼˜åŒ–"
          min_batch_size: 5
          max_wait_time: "300s"
          
        - name: "preemptive_scheduling"
          description: "æŠ¢å å¼è°ƒåº¦"
          enable_preemption: true
          priority_threshold: 50
          
        - name: "deadline_aware_scheduling"
          description: "æˆªæ­¢æ—¶é—´æ„ŸçŸ¥è°ƒåº¦"
          deadline_buffer: "10%"        # 10%æ—¶é—´ç¼“å†²
```

## æ€»ç»“ï¼šCI/CDæ™ºèƒ½åŒ–çš„æœªæ¥ä¹‹è·¯

é€šè¿‡Claude Codeçš„æ·±åº¦é›†æˆï¼Œä½ å·²ç»æŒæ¡äº†ï¼š

### ğŸ¯ æ™ºèƒ½CI/CDæ ¸å¿ƒèƒ½åŠ›

1. **æ™ºèƒ½å†³ç­–å¼•æ“**ï¼šåŸºäºAIçš„å‘å¸ƒé£é™©è¯„ä¼°å’Œç­–ç•¥æ¨è
2. **è‡ªé€‚åº”æµ‹è¯•ä¼˜åŒ–**ï¼šæ ¹æ®ä»£ç å˜æ›´æ™ºèƒ½é€‰æ‹©å’Œè°ƒåº¦æµ‹è¯•
3. **é¢„æµ‹æ€§éƒ¨ç½²ç®¡ç†**ï¼šæå‰è¯†åˆ«é£é™©å¹¶è‡ªåŠ¨è°ƒæ•´éƒ¨ç½²ç­–ç•¥
4. **è‡ªä¸»æ•…éšœæ¢å¤**ï¼šå®æ—¶ç›‘æ§å’Œè‡ªåŠ¨å›æ»šå†³ç­–ç³»ç»Ÿ
5. **æŒç»­å­¦ä¹ æ”¹è¿›**ï¼šåŸºäºå†å²æ•°æ®ä¸æ–­ä¼˜åŒ–CI/CDæµç¨‹

### âš¡ æ™ºèƒ½åŒ–æ•ˆæœå¯¹æ¯”

| CI/CDç¯èŠ‚ | ä¼ ç»Ÿæ–¹å¼ | AIå¢å¼º | æ•ˆç‡æå‡ |
|----------|----------|--------|----------|
| ä»£ç å®¡æŸ¥ | 30-60åˆ†é’Ÿ | 5-10åˆ†é’Ÿ | 70-85% |
| æµ‹è¯•é€‰æ‹© | å›ºå®šå¥—ä»¶ | æ™ºèƒ½é€‰æ‹© | 40-60% |
| éƒ¨ç½²å†³ç­– | äººå·¥åˆ¤æ–­ | AIæ¨è | å®æ—¶å†³ç­– |
| æ•…éšœå¤„ç† | è¢«åŠ¨å“åº” | ä¸»åŠ¨é¢„é˜² | 90%+ |
| æµç¨‹ä¼˜åŒ– | å­£åº¦è°ƒæ•´ | æŒç»­æ”¹è¿› | æŒç»­æå‡ |

### ğŸ› ï¸ æ™ºèƒ½CI/CDå·¥å…·é“¾

- **æ™ºèƒ½åˆ†æ**ï¼šä»£ç å˜æ›´å½±å“åˆ†æå’Œé£é™©è¯„ä¼°
- **åŠ¨æ€è°ƒåº¦**ï¼šåŸºäºè´Ÿè½½å’Œä¼˜å…ˆçº§çš„æ™ºèƒ½èµ„æºåˆ†é…
- **è‡ªé€‚åº”æµ‹è¯•**ï¼šæ™ºèƒ½æµ‹è¯•é€‰æ‹©å’Œå¹¶è¡ŒåŒ–æ‰§è¡Œ
- **é¢„æµ‹æ€§éƒ¨ç½²**ï¼šåŸºäºå†å²æ•°æ®çš„éƒ¨ç½²ç­–ç•¥ä¼˜åŒ–
- **è‡ªä¸»è¿ç»´**ï¼šå®æ—¶ç›‘æ§å’Œè‡ªåŠ¨æ•…éšœæ¢å¤

### ğŸš€ DevOpsæ–‡åŒ–å‡çº§

1. **æ•°æ®é©±åŠ¨å†³ç­–**ï¼šåŸºäºå®æ—¶æ•°æ®å’ŒAIåˆ†æçš„ç§‘å­¦å†³ç­–
2. **é¢„é˜²æ€§æ€ç»´**ï¼šä»è¢«åŠ¨å“åº”è½¬å‘ä¸»åŠ¨é¢„é˜²
3. **æŒç»­å­¦ä¹ æ”¹è¿›**ï¼šAIé©±åŠ¨çš„æµç¨‹æŒç»­ä¼˜åŒ–
4. **æ™ºèƒ½åä½œ**ï¼šäººæœºåä½œçš„æ–°å‹DevOpsæ¨¡å¼
5. **ä»·å€¼å¯¼å‘**ï¼šä¸“æ³¨äºä¸šåŠ¡ä»·å€¼äº¤ä»˜è€Œéå·¥å…·æ“ä½œ

é€šè¿‡Claude Codeçš„æ™ºèƒ½CI/CDé›†æˆï¼Œæˆ‘ä»¬ä¸ä»…å®ç°äº†è½¯ä»¶äº¤ä»˜æµç¨‹çš„è‡ªåŠ¨åŒ–ï¼Œæ›´é‡è¦çš„æ˜¯å¼•å…¥äº†**æ™ºèƒ½å†³ç­–å’Œè‡ªä¸»å­¦ä¹ èƒ½åŠ›**ã€‚è¿™ç§æ™ºèƒ½åŒ–çš„DevOpså®è·µå°†æ˜¾è‘—æå‡å›¢é˜Ÿçš„äº¤ä»˜æ•ˆç‡ã€ä»£ç è´¨é‡å’Œç³»ç»Ÿç¨³å®šæ€§ï¼Œè®©å¼€å‘å›¢é˜Ÿèƒ½å¤Ÿä¸“æ³¨äºåˆ›æ–°å’Œä¸šåŠ¡ä»·å€¼åˆ›é€ ã€‚

åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢ç´¢ä¼ä¸šå®‰å…¨ä¸æƒé™ç®¡ç†ï¼Œå­¦ä¹ å¦‚ä½•åœ¨AIé©±åŠ¨çš„å¼€å‘ç¯å¢ƒä¸­å»ºç«‹å¼ºå¤§çš„å®‰å…¨ä¿éšœä½“ç³»ã€‚

## ç›¸å…³æ–‡ç« æ¨è

- [å›¢é˜Ÿåä½œï¼šå¤šäººå¼€å‘ç¯å¢ƒé…ç½®](23-å›¢é˜Ÿåä½œå¤šäººå¼€å‘ç¯å¢ƒé…ç½®.md)
- [ä¼ä¸šå®‰å…¨ï¼šæƒé™ç®¡ç†ä¸æ•°æ®ä¿æŠ¤](25-ä¼ä¸šå®‰å…¨æƒé™ç®¡ç†ä¸æ•°æ®ä¿æŠ¤.md)
- [ç›‘æ§ä¸è¿ç»´ï¼šç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ](27-ç›‘æ§ä¸è¿ç»´ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ.md)
- [DevOpså·¥å…·é“¾é›†æˆæ¡ˆä¾‹](32-DevOpså·¥å…·é“¾é›†æˆæ¡ˆä¾‹.md)

---

*æœ¬æ–‡æ˜¯ã€ŠClaude Code å®Œæ•´æ•™ç¨‹ç³»åˆ—ã€‹çš„ç¬¬äºŒåå››éƒ¨åˆ†ã€‚æŒæ¡äº†æ™ºèƒ½CI/CDé›†æˆï¼Œè®©æˆ‘ä»¬ç»§ç»­æ¢ç´¢ä¼ä¸šçº§å®‰å…¨ç®¡ç†çš„æœ€ä½³å®è·µï¼*