---
layout: post
title: "MCPåè®®ï¼šè¿æ¥å¤–éƒ¨å·¥å…·çš„æ¡¥æ¢ï¼Œè®©Claude Codeæˆä¸ºä½ çš„å…¨èƒ½å¼€å‘ä¼™ä¼´"
date: 2025-08-17 06:00:00 +0800
tags: [Claude Code, MCPåè®®, å¤–éƒ¨å·¥å…·é›†æˆ, APIè¿æ¥, å¼€å‘æ•ˆç‡]
excerpt: "æ·±å…¥æ¢ç´¢Model Context Protocol (MCP)çš„å¼ºå¤§åŠŸèƒ½ï¼Œä»åŸºç¡€æ¦‚å¿µåˆ°é«˜çº§åº”ç”¨ï¼Œå­¦ä¼šå¦‚ä½•å°†Claude Codeä¸8000å¤šä¸ªå¤–éƒ¨å·¥å…·æ— ç¼é›†æˆï¼Œæ‰“é€ å±äºä½ çš„æ™ºèƒ½å¼€å‘ç”Ÿæ€ç³»ç»Ÿã€‚"
---

## å¼•è¨€ï¼šæ‰“ç ´å·¥å…·å­¤å²›çš„AIæ—¶ä»£

> "å·¥å…·çš„åŠ›é‡ä¸åœ¨äºå·¥å…·æœ¬èº«ï¼Œè€Œåœ¨äºå·¥å…·ä¹‹é—´çš„è¿æ¥ã€‚" â€”â€” Kevin Kelly

åœ¨ç°ä»£è½¯ä»¶å¼€å‘ä¸­ï¼Œå¼€å‘è€…éœ€è¦ä½¿ç”¨æ•°åç§ä¸åŒçš„å·¥å…·ï¼šGitHubç®¡ç†ä»£ç ã€Jiraè·Ÿè¸ªéœ€æ±‚ã€Sentryç›‘æ§é”™è¯¯ã€Slackå›¢é˜Ÿåä½œã€‚**å·¥å…·çš„åˆ†æ•£å¯¼è‡´äº†ä¸¥é‡çš„ä¸Šä¸‹æ–‡åˆ‡æ¢æˆæœ¬**â€”â€”ä½ éœ€è¦åœ¨ä¸åŒçš„å¹³å°é—´åå¤è·³è½¬ã€æ‰‹åŠ¨å¤åˆ¶ä¿¡æ¯ã€é‡æ–°å»ºç«‹ä¸Šä¸‹æ–‡ã€‚

Claude Codeçš„MCPï¼ˆModel Context Protocolï¼‰åè®®å½»åº•æ”¹å˜äº†è¿™ç§çŠ¶å†µã€‚MCPå°±åƒæ˜¯AIç•Œçš„"USB-C"ï¼Œä¸ºAIæ¨¡å‹æä¾›äº†è¿æ¥å¤–éƒ¨å·¥å…·çš„é€šç”¨æ ‡å‡†ã€‚**è®©Claude Codeä»ä¸€ä¸ªå­¤ç«‹çš„ç¼–ç¨‹åŠ©æ‰‹ï¼Œå˜æˆäº†èƒ½å¤Ÿè®¿é—®ä½ æ•´ä¸ªå¼€å‘å·¥å…·é“¾çš„æ™ºèƒ½ä¼™ä¼´**ã€‚

è¿™ç¯‡æ–‡ç« å°†å…¨é¢è§£æMCPåè®®çš„åŸç†ã€é…ç½®ã€åº”ç”¨å’Œæœ€ä½³å®è·µï¼Œè®©ä½ çš„Claude CodeçœŸæ­£æˆä¸ºå¼€å‘ç”Ÿæ€çš„ä¸­å¿ƒæ¢çº½ã€‚

## MCPåè®®æ¦‚è¿°

### ä¼ ç»Ÿå·¥å…·é›†æˆçš„ç—›ç‚¹

```
ä¼ ç»Ÿå¼€å‘å·¥ä½œæµçš„é—®é¢˜ï¼š
1. å·¥å…·åˆ†æ•£ â†’ ä¸åŒå¹³å°ï¼Œå„è‡ªå­¤ç«‹
2. ä¸Šä¸‹æ–‡ä¸¢å¤± â†’ åˆ‡æ¢å¹³å°æ—¶ä¸¢å¤±å·¥ä½œçŠ¶æ€  
3. ä¿¡æ¯é‡å¤ â†’ éœ€è¦åœ¨å·¥å…·é—´æ‰‹åŠ¨å¤åˆ¶ç²˜è´´
4. æ•ˆç‡ä½ä¸‹ â†’ èŠ±è´¹å¤§é‡æ—¶é—´åœ¨å·¥å…·åˆ‡æ¢ä¸Š
5. è®¤çŸ¥è´Ÿè· â†’ éœ€è¦è®°ä½å¤šä¸ªå·¥å…·çš„æ“ä½œæ–¹å¼

å¼€å‘åœºæ™¯ä¸¾ä¾‹ï¼š
- ä»GitHubçœ‹åˆ°BugæŠ¥å‘Š (å¹³å°1)
- åœ¨Jiraåˆ›å»ºå·¥å•è·Ÿè¸ª (å¹³å°2)  
- åœ¨IDEä¸­æŸ¥çœ‹ç›¸å…³ä»£ç  (å¹³å°3)
- åœ¨SentryæŸ¥çœ‹é”™è¯¯å †æ ˆ (å¹³å°4)
- åœ¨Slackä¸å›¢é˜Ÿè®¨è®º (å¹³å°5)

æ¯ä¸ªæ­¥éª¤éƒ½éœ€è¦æ‰‹åŠ¨åˆ‡æ¢å’Œä¿¡æ¯ä¼ é€’ ğŸ˜¤
```

### MCPåè®®çš„é©å‘½æ€§ä»·å€¼

```
MCPç»Ÿä¸€å·¥å…·ç”Ÿæ€çš„ä¼˜åŠ¿ï¼š
1. ç»Ÿä¸€æ¥å£ â†’ ä¸€ä¸ªåè®®ï¼Œè¿æ¥æ‰€æœ‰å·¥å…·
2. ä¸Šä¸‹æ–‡è¿è´¯ â†’ AIåŠ©æ‰‹ç†è§£å®Œæ•´çš„å·¥ä½œæµç¨‹
3. è‡ªåŠ¨åŒ–æ“ä½œ â†’ AIå¯ä»¥è·¨å·¥å…·æ‰§è¡Œå¤æ‚ä»»åŠ¡
4. å®æ—¶åŒæ­¥ â†’ å·¥å…·çŠ¶æ€çš„å³æ—¶æ›´æ–°å’Œåé¦ˆ
5. æ™ºèƒ½åˆ†æ â†’ åŸºäºå¤šå·¥å…·æ•°æ®çš„æ·±åº¦æ´å¯Ÿ

ç†æƒ³å¼€å‘åœºæ™¯ï¼š
Claude Code ç›´æ¥ï¼š
- ğŸ“– è¯»å–GitHub Issueså’ŒPRä¿¡æ¯
- ğŸ” åˆ†æSentryé”™è¯¯æŠ¥å‘Šå’Œå †æ ˆè¿½è¸ª
- ğŸ“Š æŸ¥è¯¢æ•°æ®åº“çŠ¶æ€å’Œæ€§èƒ½æŒ‡æ ‡
- ğŸ’¬ åœ¨Slackå‘é€çŠ¶æ€æ›´æ–°
- ğŸ¯ åœ¨Linearåˆ›å»ºå’Œæ›´æ–°ä»»åŠ¡

æ‰€æœ‰æ“ä½œåœ¨ä¸€ä¸ªç•Œé¢å®Œæˆï¼âœ¨
```

## MCPåè®®æ ¸å¿ƒæ¶æ„

### 1. åè®®æ¶æ„è®¾è®¡

#### ç³»ç»Ÿç»„ä»¶å…³ç³»

```mermaid
graph TD
    A[Claude Code å®¢æˆ·ç«¯] --> B[MCP åè®®å±‚]
    B --> C[æœ¬åœ° MCP æœåŠ¡å™¨]
    B --> D[è¿œç¨‹ MCP æœåŠ¡å™¨]
    
    C --> E[æ–‡ä»¶ç³»ç»Ÿå·¥å…·]
    C --> F[ç»ˆç«¯å‘½ä»¤å·¥å…·]
    C --> G[æ•°æ®åº“å·¥å…·]
    
    D --> H[GitHub API]
    D --> I[Slack API]
    D --> J[Linear API]
    D --> K[Sentry API]
    
    subgraph "æœ¬åœ°å·¥å…·ç”Ÿæ€"
        E
        F
        G
    end
    
    subgraph "äº‘ç«¯æœåŠ¡ç”Ÿæ€"
        H
        I
        J
        K
    end
    
    L[è®¤è¯ç®¡ç†å™¨] --> D
    M[èµ„æºå‘ç°å™¨] --> C
    M --> D
    
    N[ä¸Šä¸‹æ–‡ç®¡ç†å™¨] --> A
    O[å·¥å…·æ³¨å†Œè¡¨] --> B
    P[å®‰å…¨æ²™ç®±] --> C
    P --> D
```

#### åè®®å·¥ä½œåŸç†

```json
// MCP æœåŠ¡å™¨èƒ½åŠ›æ¸…å•ç¤ºä¾‹
{
  "capabilities": {
    "tools": [
      {
        "name": "github_get_issue",
        "description": "è·å–GitHub Issueè¯¦ç»†ä¿¡æ¯",
        "inputSchema": {
          "type": "object",
          "properties": {
            "owner": { "type": "string", "description": "ä»“åº“æ‰€æœ‰è€…" },
            "repo": { "type": "string", "description": "ä»“åº“åç§°" },
            "issue_number": { "type": "integer", "description": "Issueç¼–å·" }
          },
          "required": ["owner", "repo", "issue_number"]
        }
      }
    ],
    "resources": [
      {
        "uri": "github://issues/active",
        "name": "æ´»è·ƒIssues",
        "description": "å½“å‰æ´»è·ƒçš„GitHub Issuesåˆ—è¡¨",
        "mimeType": "application/json"
      }
    ],
    "prompts": [
      {
        "name": "analyze_error",
        "description": "åˆ†æé”™è¯¯æŠ¥å‘Šå¹¶æä¾›ä¿®å¤å»ºè®®",
        "arguments": [
          {
            "name": "error_id",
            "description": "Sentryé”™è¯¯ID",
            "required": true
          }
        ]
      }
    ]
  }
}
```

### 2. MCPé…ç½®ç³»ç»Ÿ

#### é…ç½®æ–‡ä»¶ç»“æ„è¯¦è§£

```json
// ~/.claude/mcp_settings.json - ä¸»é…ç½®æ–‡ä»¶
{
  "mcpServers": {
    // GitHubé›†æˆé…ç½®
    "github": {
      "command": "node",
      "args": [
        "/path/to/github-mcp-server/build/index.js"
      ],
      "env": {
        "GITHUB_PERSONAL_ACCESS_TOKEN": "${GITHUB_TOKEN}"
      },
      "scope": "global",
      "description": "GitHubä»“åº“å’ŒIssueç®¡ç†"
    },
    
    // Slacké›†æˆé…ç½®
    "slack": {
      "command": "python",
      "args": [
        "/path/to/slack-mcp-server/main.py"
      ],
      "env": {
        "SLACK_BOT_TOKEN": "${SLACK_BOT_TOKEN}",
        "SLACK_APP_TOKEN": "${SLACK_APP_TOKEN}"
      },
      "scope": "project",
      "description": "å›¢é˜Ÿæ²Ÿé€šå’Œé€šçŸ¥"
    },
    
    // Sentryé”™è¯¯ç›‘æ§
    "sentry": {
      "command": "node",
      "args": [
        "/path/to/sentry-mcp-server/dist/index.js"
      ],
      "env": {
        "SENTRY_AUTH_TOKEN": "${SENTRY_TOKEN}",
        "SENTRY_ORG": "my-organization",
        "SENTRY_PROJECT": "my-project"
      },
      "scope": "project"
    },
    
    // Linearé¡¹ç›®ç®¡ç†
    "linear": {
      "command": "deno",
      "args": [
        "run",
        "--allow-net",
        "--allow-env",
        "/path/to/linear-mcp-server/mod.ts"
      ],
      "env": {
        "LINEAR_API_KEY": "${LINEAR_API_KEY}"
      },
      "scope": "team"
    },
    
    // æ•°æ®åº“æŸ¥è¯¢å·¥å…·
    "database": {
      "command": "python",
      "args": [
        "/path/to/database-mcp-server/server.py"
      ],
      "env": {
        "DATABASE_URL": "${DATABASE_URL}",
        "DB_POOL_SIZE": "10"
      },
      "scope": "local",
      "security": {
        "readOnly": true,
        "allowedTables": ["users", "orders", "products"],
        "deniedTables": ["admin_logs", "api_keys"]
      }
    }
  },
  
  // å…¨å±€é…ç½®
  "globalSettings": {
    "maxConcurrentConnections": 10,
    "connectionTimeout": 30000,
    "retryAttempts": 3,
    "logLevel": "info",
    "cacheEnabled": true,
    "cacheTTL": 300
  },
  
  // å®‰å…¨é…ç½®
  "security": {
    "enableSandbox": true,
    "allowedDomains": [
      "api.github.com",
      "slack.com",
      "sentry.io",
      "api.linear.app"
    ],
    "blockedDomains": [],
    "maxRequestSize": "10MB",
    "rateLimit": {
      "requests": 100,
      "window": 60000
    }
  }
}
```

#### ç¯å¢ƒå˜é‡ç®¡ç†

```bash
# .env - æ•æ„Ÿä¿¡æ¯ç¯å¢ƒå˜é‡
# GitHubé…ç½®
GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxx
GITHUB_USERNAME=your-username

# Slacké…ç½®
SLACK_BOT_TOKEN=xoxb-xxxxxxxxxx-xxxxxxxxxx-xxxxxxxxxxxx
SLACK_APP_TOKEN=xapp-xxxxxxxxxx-xxxxxxxxxx-xxxxxxxxxxxx
SLACK_SIGNING_SECRET=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Sentryé…ç½®
SENTRY_TOKEN=sntrys_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
SENTRY_DSN=https://xxxxxxxx@sentry.io/xxxxxxx

# Linearé…ç½®
LINEAR_API_KEY=lin_api_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://user:password@localhost:5432/mydb
REDIS_URL=redis://localhost:6379

# äº‘æœåŠ¡é…ç½®
AWS_ACCESS_KEY_ID=AKIAXXXXXXXXXXXXXXXX
AWS_SECRET_ACCESS_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
AWS_REGION=us-west-2

# ç›‘æ§å’Œæ—¥å¿—
NEWRELIC_LICENSE_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
DATADOG_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

### 3. è¿æ¥å’Œè®¤è¯æœºåˆ¶

#### OAuthè®¤è¯æµç¨‹

```yaml
# OAuthé…ç½®ç¤ºä¾‹
oauth_providers:
  github:
    client_id: "${GITHUB_CLIENT_ID}"
    client_secret: "${GITHUB_CLIENT_SECRET}"
    scopes: ["repo", "issues", "pull_requests", "user"]
    redirect_uri: "http://localhost:3000/auth/github/callback"
    
  slack:
    client_id: "${SLACK_CLIENT_ID}"
    client_secret: "${SLACK_CLIENT_SECRET}"
    scopes: ["chat:write", "channels:read", "users:read", "files:write"]
    redirect_uri: "http://localhost:3000/auth/slack/callback"
    
  linear:
    client_id: "${LINEAR_CLIENT_ID}"
    client_secret: "${LINEAR_CLIENT_SECRET}"
    scopes: ["read", "write", "issues:create"]
    redirect_uri: "http://localhost:3000/auth/linear/callback"

# è®¤è¯çŠ¶æ€ç®¡ç†
auth_tokens:
  storage_path: "~/.claude/auth_tokens.encrypted"
  encryption_key: "${AUTH_ENCRYPTION_KEY}"
  refresh_threshold: 300  # 5åˆ†é’Ÿå‰è‡ªåŠ¨åˆ·æ–°
  
  providers:
    github:
      access_token: "encrypted_token_here"
      refresh_token: "encrypted_refresh_token_here"
      expires_at: "2024-12-31T23:59:59Z"
      
    slack:
      access_token: "encrypted_token_here"
      expires_at: "never"
      team_id: "T1234567890"
      
    linear:
      access_token: "encrypted_token_here"
      expires_at: "2024-12-31T23:59:59Z"
      organization_id: "org_1234567890"
```

## å®é™…åº”ç”¨åœºæ™¯

### åœºæ™¯1ï¼šæ™ºèƒ½Bugåˆ†æå’Œä¿®å¤å·¥ä½œæµ

```bash
claude "åˆ†æGitHub Issue #123çš„é”™è¯¯ï¼Œæ£€æŸ¥ç›¸å…³çš„SentryæŠ¥å‘Šï¼Œå¹¶æä¾›ä¿®å¤å»ºè®®"
```

Claude Codeçš„å¤„ç†è¿‡ç¨‹ï¼š

```python
# MCPå·¥ä½œæµè‡ªåŠ¨åŒ–ç¤ºä¾‹
async def analyze_bug_workflow(issue_number: int):
    """æ™ºèƒ½Bugåˆ†æå·¥ä½œæµ"""
    
    # 1. ä»GitHubè·å–Issueè¯¦æƒ…
    github_issue = await mcp.github.get_issue(
        owner="myorg", 
        repo="myproject", 
        issue_number=issue_number
    )
    
    print(f"ğŸ“‹ GitHub Issue #{issue_number}: {github_issue.title}")
    print(f"çŠ¶æ€: {github_issue.state} | æ ‡ç­¾: {github_issue.labels}")
    print(f"æè¿°: {github_issue.body[:200]}...")
    
    # 2. æœç´¢ç›¸å…³çš„Sentryé”™è¯¯
    error_keywords = extract_error_keywords(github_issue.body)
    sentry_errors = await mcp.sentry.search_errors(
        query=error_keywords,
        time_range="7d",
        limit=10
    )
    
    if sentry_errors:
        print(f"ğŸ” å‘ç° {len(sentry_errors)} ä¸ªç›¸å…³Sentryé”™è¯¯:")
        for error in sentry_errors[:3]:
            print(f"  - {error.title} (å‘ç”Ÿ {error.count} æ¬¡)")
            
        # 3. è·å–æœ€é¢‘ç¹é”™è¯¯çš„è¯¦ç»†ä¿¡æ¯
        top_error = sentry_errors[0]
        error_details = await mcp.sentry.get_error_details(top_error.id)
        
        print(f"ğŸ“Š é”™è¯¯è¯¦æƒ…åˆ†æ:")
        print(f"  é”™è¯¯ç±»å‹: {error_details.exception_type}")
        print(f"  é”™è¯¯ä¿¡æ¯: {error_details.exception_value}")
        print(f"  å‘ç”Ÿé¢‘ç‡: {error_details.frequency}")
        print(f"  å½±å“ç”¨æˆ·: {error_details.affected_users}")
        
        # 4. åˆ†æå †æ ˆè·Ÿè¸ª
        stack_trace = error_details.stack_trace
        relevant_files = await analyze_stack_trace(stack_trace)
        
        print(f"ğŸ”§ ç›¸å…³ä»£ç æ–‡ä»¶:")
        for file_info in relevant_files:
            print(f"  - {file_info.filename}:{file_info.line}")
    
    # 5. æ£€æŸ¥ä»£ç å˜æ›´å†å²
    recent_commits = await mcp.github.get_recent_commits(
        owner="myorg",
        repo="myproject", 
        path=relevant_files[0].filename,
        since="7 days ago"
    )
    
    if recent_commits:
        print(f"ğŸ“ˆ æœ€è¿‘ç›¸å…³æäº¤:")
        for commit in recent_commits[:3]:
            print(f"  - {commit.sha[:8]}: {commit.message}")
            print(f"    ä½œè€…: {commit.author.name} | æ—¶é—´: {commit.date}")
    
    # 6. ç”Ÿæˆä¿®å¤å»ºè®®
    fix_suggestions = await generate_fix_suggestions(
        issue=github_issue,
        errors=sentry_errors,
        code_context=relevant_files,
        recent_changes=recent_commits
    )
    
    print(f"ğŸ’¡ ä¿®å¤å»ºè®®:")
    for i, suggestion in enumerate(fix_suggestions, 1):
        print(f"  {i}. {suggestion.title}")
        print(f"     {suggestion.description}")
        print(f"     ä¼˜å…ˆçº§: {suggestion.priority}")
        print(f"     é¢„ä¼°æ—¶é—´: {suggestion.estimated_time}")
    
    # 7. åœ¨Linearä¸­åˆ›å»ºä»»åŠ¡ï¼ˆå¯é€‰ï¼‰
    if input("æ˜¯å¦åœ¨Linearä¸­åˆ›å»ºä¿®å¤ä»»åŠ¡? (y/n): ").lower() == 'y':
        linear_issue = await mcp.linear.create_issue(
            title=f"ä¿®å¤: {github_issue.title}",
            description=f"""
## GitHub Issue
#{issue_number}: {github_issue.url}

## Sentryé”™è¯¯
- {top_error.title}
- å‘ç”Ÿæ¬¡æ•°: {top_error.count}
- å½±å“ç”¨æˆ·: {error_details.affected_users}

## ä¿®å¤å»ºè®®
{format_suggestions_for_linear(fix_suggestions)}

## ç›¸å…³æ–‡ä»¶
{format_files_for_linear(relevant_files)}
            """,
            priority="High" if error_details.affected_users > 100 else "Medium",
            labels=["bug", "github-sync"],
            assignee="current_user"
        )
        
        print(f"âœ… Linearä»»åŠ¡å·²åˆ›å»º: {linear_issue.url}")
        
        # 8. åœ¨GitHub Issueä¸­æ·»åŠ Linearé“¾æ¥
        await mcp.github.add_comment(
            owner="myorg",
            repo="myproject",
            issue_number=issue_number,
            body=f"ğŸ”— å·²åœ¨Linearä¸­åˆ›å»ºè·Ÿè¸ªä»»åŠ¡: {linear_issue.url}"
        )
        
    # 9. å‘é€å›¢é˜Ÿé€šçŸ¥ï¼ˆå¯é€‰ï¼‰
    if input("æ˜¯å¦å‘é€Slacké€šçŸ¥? (y/n): ").lower() == 'y':
        await mcp.slack.send_message(
            channel="#engineering",
            text=f"""
ğŸ› **Bugåˆ†æå®Œæˆ**

**GitHub Issue**: #{issue_number} - {github_issue.title}
**Sentryé”™è¯¯**: {top_error.count}æ¬¡å‘ç”Ÿï¼Œå½±å“{error_details.affected_users}ç”¨æˆ·
**ä¿®å¤ä¼˜å…ˆçº§**: {"ğŸ”´ é«˜" if error_details.affected_users > 100 else "ğŸŸ¡ ä¸­"}

**å»ºè®®ä¿®å¤æ–¹æ¡ˆ**: {fix_suggestions[0].title}
**é¢„ä¼°å·¥ä½œé‡**: {fix_suggestions[0].estimated_time}

è¯¦æƒ…è¯·æŸ¥çœ‹: {github_issue.url}
            """
        )
        
        print("ğŸ“¢ Slacké€šçŸ¥å·²å‘é€")
    
    return {
        "issue": github_issue,
        "errors": sentry_errors,
        "suggestions": fix_suggestions,
        "linear_task": linear_issue if 'linear_issue' in locals() else None
    }

# ä½¿ç”¨ç¤ºä¾‹
result = await analyze_bug_workflow(123)
```

### åœºæ™¯2ï¼šè‡ªåŠ¨åŒ–é¡¹ç›®çŠ¶æ€åŒæ­¥

```bash
claude "æ£€æŸ¥æœ¬å‘¨çš„å¼€å‘è¿›åº¦ï¼Œæ›´æ–°Linearé¡¹ç›®çŠ¶æ€ï¼Œå¹¶åœ¨Slackæ±‡æŠ¥"
```

å®ç°çš„è‡ªåŠ¨åŒ–å·¥ä½œæµï¼š

```python
async def weekly_progress_sync():
    """æ¯å‘¨é¡¹ç›®è¿›åº¦åŒæ­¥å·¥ä½œæµ"""
    
    print("ğŸ“Š å¼€å§‹æ”¶é›†æœ¬å‘¨å¼€å‘è¿›åº¦æ•°æ®...")
    
    # 1. è·å–GitHubæœ¬å‘¨æ´»åŠ¨
    week_ago = datetime.now() - timedelta(days=7)
    github_activity = await mcp.github.get_activity_summary(
        organization="myorg",
        since=week_ago.isoformat(),
        metrics=["commits", "prs", "reviews", "issues"]
    )
    
    print(f"ğŸ“ˆ GitHubæœ¬å‘¨æ´»åŠ¨:")
    print(f"  - æäº¤æ•°: {github_activity.commits}")
    print(f"  - PRæ•°é‡: {github_activity.pull_requests}")
    print(f"  - ä»£ç å®¡æŸ¥: {github_activity.reviews}")
    print(f"  - è§£å†³Issue: {github_activity.closed_issues}")
    
    # 2. è·å–Linearä»»åŠ¡è¿›åº¦
    linear_progress = await mcp.linear.get_team_progress(
        team_id="team_123",
        time_range="week",
        include_metrics=True
    )
    
    completed_tasks = linear_progress.completed_issues
    in_progress_tasks = linear_progress.in_progress_issues
    
    print(f"ğŸ“‹ Linearä»»åŠ¡è¿›åº¦:")
    print(f"  - å·²å®Œæˆ: {len(completed_tasks)}")
    print(f"  - è¿›è¡Œä¸­: {len(in_progress_tasks)}")
    print(f"  - å®Œæˆç‡: {linear_progress.completion_rate:.1%}")
    
    # 3. åˆ†æä»£ç è´¨é‡æŒ‡æ ‡
    quality_metrics = await mcp.sonarqube.get_quality_gate_status()
    sentry_health = await mcp.sentry.get_project_health()
    
    print(f"ğŸ” ä»£ç è´¨é‡æŒ‡æ ‡:")
    print(f"  - SonarQubeçŠ¶æ€: {quality_metrics.status}")
    print(f"  - æŠ€æœ¯å€ºåŠ¡: {quality_metrics.technical_debt}")
    print(f"  - é”™è¯¯ç‡å˜åŒ–: {sentry_health.error_rate_change}%")
    
    # 4. ç”Ÿæˆè¿›åº¦æŠ¥å‘Š
    progress_report = generate_progress_report(
        github_activity=github_activity,
        linear_progress=linear_progress,
        quality_metrics=quality_metrics,
        sentry_health=sentry_health
    )
    
    # 5. æ›´æ–°Linearé¡¹ç›®çŠ¶æ€
    await mcp.linear.update_project_status(
        project_id="proj_123",
        progress_percentage=linear_progress.completion_rate * 100,
        status_update=progress_report.summary,
        health_indicator=calculate_project_health(
            quality_metrics, sentry_health
        )
    )
    
    print("âœ… Linearé¡¹ç›®çŠ¶æ€å·²æ›´æ–°")
    
    # 6. å‘é€Slackæ¯å‘¨æŠ¥å‘Š
    slack_report = format_slack_report(progress_report)
    await mcp.slack.send_message(
        channel="#weekly-updates",
        blocks=slack_report.blocks,
        attachments=slack_report.attachments
    )
    
    print("ğŸ“¢ Slackæ¯å‘¨æŠ¥å‘Šå·²å‘é€")
    
    # 7. è¯†åˆ«éœ€è¦å…³æ³¨çš„é—®é¢˜
    attention_items = identify_attention_items(
        github_activity, linear_progress, quality_metrics
    )
    
    if attention_items:
        print(f"âš ï¸ éœ€è¦å…³æ³¨çš„é—®é¢˜:")
        for item in attention_items:
            print(f"  - {item.title}: {item.description}")
            
        # å‘é€å•ç‹¬çš„è­¦å‘Šé€šçŸ¥
        await mcp.slack.send_message(
            channel="#engineering-alerts",
            text="ğŸš¨ **æœ¬å‘¨éœ€è¦å…³æ³¨çš„é—®é¢˜**",
            blocks=format_attention_items(attention_items)
        )
    
    return progress_report

# å®šæ—¶æ‰§è¡Œï¼ˆæ¯å‘¨äº”ä¸‹åˆï¼‰
schedule.every().friday.at("17:00").do(weekly_progress_sync)
```

### åœºæ™¯3ï¼šæ™ºèƒ½å®¢æˆ·æ”¯æŒå·¥ä½œæµ

```bash
claude "@sentry è·å–æœ€è¿‘24å°æ—¶çš„ç”¨æˆ·æŠ¥å‘Šé”™è¯¯ï¼Œåˆ†æå½±å“é¢å¹¶åˆ›å»ºå¯¹åº”çš„GitHub Issues"
```

å®ç°çš„å®¢æˆ·æ”¯æŒè‡ªåŠ¨åŒ–ï¼š

```python
async def customer_support_workflow():
    """æ™ºèƒ½å®¢æˆ·æ”¯æŒå·¥ä½œæµ"""
    
    print("ğŸ› ï¸ å¼€å§‹åˆ†æç”¨æˆ·æŠ¥å‘Šçš„é—®é¢˜...")
    
    # 1. ä»å¤šä¸ªæ¸ é“æ”¶é›†ç”¨æˆ·åé¦ˆ
    feedback_sources = await collect_user_feedback_sources()
    
    # Sentryç”¨æˆ·æŠ¥å‘Šçš„é”™è¯¯
    user_errors = await mcp.sentry.get_user_feedback_errors(
        time_range="24h",
        min_user_reports=2  # è‡³å°‘2ä¸ªç”¨æˆ·æŠ¥å‘Š
    )
    
    # Zendeskå®¢æœå·¥å•
    support_tickets = await mcp.zendesk.get_technical_tickets(
        status=["new", "open"],
        priority=["high", "urgent"],
        tags=["bug", "error"]
    )
    
    # Slackç”¨æˆ·åé¦ˆé¢‘é“
    slack_feedback = await mcp.slack.get_channel_messages(
        channel="#user-feedback",
        time_range="24h",
        filter_keywords=["error", "bug", "broken", "issue"]
    )
    
    print(f"ğŸ“¥ æ”¶é›†åˆ°åé¦ˆ:")
    print(f"  - Sentryç”¨æˆ·é”™è¯¯: {len(user_errors)}")
    print(f"  - ZendeskæŠ€æœ¯å·¥å•: {len(support_tickets)}")  
    print(f"  - Slackç”¨æˆ·åé¦ˆ: {len(slack_feedback)}")
    
    # 2. æ™ºèƒ½åˆ†æå’Œåˆ†ç±»
    analyzed_issues = []
    
    for error in user_errors:
        # åˆ†æé”™è¯¯å½±å“é¢
        impact_analysis = await analyze_error_impact(error)
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸å…³GitHub Issue
        existing_issues = await mcp.github.search_issues(
            query=f"is:issue {error.fingerprint}",
            state="open"
        )
        
        if not existing_issues:
            # åˆ›å»ºæ–°çš„GitHub Issue
            issue_description = await generate_issue_description(
                error=error,
                impact=impact_analysis,
                user_reports=error.user_reports
            )
            
            github_issue = await mcp.github.create_issue(
                owner="myorg",
                repo="myproject",
                title=f"User Reported: {error.title}",
                body=issue_description,
                labels=["user-reported", "priority-" + impact_analysis.priority],
                assignees=determine_assignees(error.stack_trace)
            )
            
            # æ·»åŠ Sentryé“¾æ¥åˆ°Issue
            await mcp.github.add_comment(
                owner="myorg",
                repo="myproject", 
                issue_number=github_issue.number,
                body=f"ğŸ”— Sentryé”™è¯¯é“¾æ¥: {error.permalink}"
            )
            
            analyzed_issues.append({
                "github_issue": github_issue,
                "sentry_error": error,
                "impact": impact_analysis,
                "type": "new_issue"
            })
            
            print(f"âœ… åˆ›å»ºGitHub Issue #{github_issue.number}")
            
        else:
            # æ›´æ–°ç°æœ‰Issueçš„å½±å“æ•°æ®
            await mcp.github.add_comment(
                owner="myorg",
                repo="myproject",
                issue_number=existing_issues[0].number,
                body=f"ğŸ“Š **å½±å“æ›´æ–°** (è¿‡å»24å°æ—¶)\n" +
                      f"- æ–°å¢ç”¨æˆ·æŠ¥å‘Š: {len(error.new_user_reports)}\n" +
                      f"- æ€»å½±å“ç”¨æˆ·: {impact_analysis.total_users}\n" +
                      f"- é”™è¯¯é¢‘ç‡: {error.frequency}/hour"
            )
            
            analyzed_issues.append({
                "github_issue": existing_issues[0],
                "sentry_error": error,
                "impact": impact_analysis,
                "type": "updated_issue"
            })
            
            print(f"ğŸ”„ æ›´æ–°GitHub Issue #{existing_issues[0].number}")
    
    # 3. å¤„ç†æ”¯æŒå·¥å•
    for ticket in support_tickets:
        # å°è¯•ä¸å·²çŸ¥é”™è¯¯å…³è”
        related_errors = await find_related_sentry_errors(ticket.description)
        
        if related_errors:
            # åœ¨å·¥å•ä¸­æ·»åŠ æŠ€æœ¯åˆ†æä¿¡æ¯
            technical_analysis = await generate_technical_analysis(
                ticket=ticket,
                errors=related_errors
            )
            
            await mcp.zendesk.add_ticket_comment(
                ticket_id=ticket.id,
                comment=f"""
## ğŸ” æŠ€æœ¯åˆ†æ (ç”±AIè‡ªåŠ¨ç”Ÿæˆ)

**å…³è”é”™è¯¯**: {related_errors[0].title}
**é”™è¯¯é¢‘ç‡**: {related_errors[0].count} æ¬¡/24å°æ—¶
**å½±å“è¯„ä¼°**: {technical_analysis.severity}

**å¯èƒ½åŸå› **: 
{technical_analysis.possible_causes}

**ä¸´æ—¶è§£å†³æ–¹æ¡ˆ**: 
{technical_analysis.workarounds}

**æ°¸ä¹…ä¿®å¤è¿›å±•**: 
- GitHub Issue: {technical_analysis.github_issue_link}
- é¢„è®¡ä¿®å¤æ—¶é—´: {technical_analysis.eta}

---
*æ­¤åˆ†æç”±Claude Code MCPç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
                """,
                internal=True  # å†…éƒ¨å¤‡æ³¨
            )
            
            print(f"ğŸ« å·¥å• #{ticket.id} å·²æ·»åŠ æŠ€æœ¯åˆ†æ")
    
    # 4. ç”Ÿæˆå½±å“é¢æŠ¥å‘Š
    impact_report = generate_impact_report(analyzed_issues)
    
    # 5. å‘é€å›¢é˜Ÿé€šçŸ¥
    if analyzed_issues:
        priority_issues = [
            issue for issue in analyzed_issues 
            if issue["impact"].priority in ["high", "urgent"]
        ]
        
        if priority_issues:
            await mcp.slack.send_message(
                channel="#engineering-urgent",
                text="ğŸš¨ **é«˜ä¼˜å…ˆçº§ç”¨æˆ·æŠ¥å‘Šé—®é¢˜**",
                blocks=format_priority_issues_alert(priority_issues)
            )
        
        # å‘é€æ¯æ—¥å½±å“æŠ¥å‘Š
        await mcp.slack.send_message(
            channel="#user-impact",
            text="ğŸ“Š **ç”¨æˆ·å½±å“æ—¥æŠ¥**",
            blocks=format_impact_report(impact_report)
        )
    
    # 6. è‡ªåŠ¨åˆ†æ´¾ä»»åŠ¡
    for issue_data in analyzed_issues:
        if issue_data["impact"].priority == "urgent":
            # åˆ›å»ºLinearç´§æ€¥ä»»åŠ¡
            linear_task = await mcp.linear.create_issue(
                title=f"ğŸš¨ ç´§æ€¥ä¿®å¤: {issue_data['sentry_error'].title}",
                description=f"""
## ç”¨æˆ·å½±å“
- å½±å“ç”¨æˆ·æ•°: {issue_data['impact'].affected_users}
- é”™è¯¯é¢‘ç‡: {issue_data['sentry_error'].frequency}/hour
- ä¸šåŠ¡å½±å“: {issue_data['impact'].business_impact}

## æŠ€æœ¯è¯¦æƒ…  
- GitHub Issue: {issue_data['github_issue'].html_url}
- Sentryé“¾æ¥: {issue_data['sentry_error'].permalink}

## SLAè¦æ±‚
æ­¤é—®é¢˜éœ€è¦åœ¨4å°æ—¶å†…å“åº”ï¼Œ24å°æ—¶å†…ä¿®å¤ã€‚
                """,
                priority="Urgent",
                labels=["user-impact", "sla-critical"],
                team_id="engineering_team",
                assignee=issue_data["impact"].suggested_assignee
            )
            
            print(f"ğŸ¯ åˆ›å»ºLinearç´§æ€¥ä»»åŠ¡: {linear_task.identifier}")
    
    return {
        "analyzed_issues": len(analyzed_issues),
        "priority_issues": len([i for i in analyzed_issues if i["impact"].priority in ["high", "urgent"]]),
        "impact_report": impact_report
    }

# è‡ªåŠ¨æ‰§è¡Œï¼ˆæ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡ï¼‰
schedule.every().hour.do(customer_support_workflow)
```

## é«˜çº§MCPåº”ç”¨æ¨¡å¼

### 1. å¤šæœåŠ¡ç¼–æ’å·¥ä½œæµ

#### å¤æ‚ä¸šåŠ¡æµç¨‹è‡ªåŠ¨åŒ–

```python
# å‘å¸ƒæµç¨‹è‡ªåŠ¨åŒ–ç¤ºä¾‹
async def automated_release_workflow(version: str, release_notes: str):
    """è‡ªåŠ¨åŒ–å‘å¸ƒæµç¨‹"""
    
    workflow_id = f"release-{version}-{int(time.time())}"
    print(f"ğŸš€ å¼€å§‹å‘å¸ƒæµç¨‹: {version} (ID: {workflow_id})")
    
    try:
        # ç¬¬1æ­¥ï¼šé¢„å‘å¸ƒæ£€æŸ¥
        print("ğŸ“‹ æ‰§è¡Œé¢„å‘å¸ƒæ£€æŸ¥...")
        
        # æ£€æŸ¥ä»£ç è´¨é‡é—¨ç¦
        quality_status = await mcp.sonarqube.get_quality_gate_status()
        if quality_status.status != "PASSED":
            raise Exception(f"ä»£ç è´¨é‡æ£€æŸ¥å¤±è´¥: {quality_status.conditions}")
        
        # æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡
        coverage_report = await mcp.codecov.get_coverage_report()
        if coverage_report.total_coverage < 85:
            raise Exception(f"æµ‹è¯•è¦†ç›–ç‡ä¸è¶³: {coverage_report.total_coverage}%")
        
        # æ£€æŸ¥å®‰å…¨æ‰«æ
        security_scan = await mcp.snyk.run_security_scan()
        if security_scan.high_severity_issues > 0:
            raise Exception(f"å‘ç°{security_scan.high_severity_issues}ä¸ªé«˜å±å®‰å…¨é—®é¢˜")
        
        print("âœ… é¢„å‘å¸ƒæ£€æŸ¥é€šè¿‡")
        
        # ç¬¬2æ­¥ï¼šæ›´æ–°ç‰ˆæœ¬ä¿¡æ¯
        print(f"ğŸ“ æ›´æ–°ç‰ˆæœ¬ä¿¡æ¯åˆ° {version}...")
        
        # æ›´æ–°package.json
        await update_version_files(version)
        
        # æäº¤ç‰ˆæœ¬æ›´æ–°
        commit_result = await mcp.github.create_commit(
            owner="myorg",
            repo="myproject",
            message=f"chore: bump version to {version}",
            files=[
                {"path": "package.json", "content": await read_file("package.json")},
                {"path": "CHANGELOG.md", "content": await generate_changelog(version, release_notes)}
            ]
        )
        
        print(f"âœ… ç‰ˆæœ¬æäº¤: {commit_result.sha}")
        
        # ç¬¬3æ­¥ï¼šåˆ›å»ºGitHub Release
        print("ğŸ·ï¸ åˆ›å»ºGitHub Release...")
        
        github_release = await mcp.github.create_release(
            owner="myorg",
            repo="myproject",
            tag_name=f"v{version}",
            name=f"Release {version}",
            body=release_notes,
            draft=False,
            prerelease=version.count('alpha') > 0 or version.count('beta') > 0
        )
        
        print(f"âœ… GitHub Releaseåˆ›å»ºæˆåŠŸ: {github_release.html_url}")
        
        # ç¬¬4æ­¥ï¼šæ„å»ºå’Œéƒ¨ç½²
        print("ğŸ—ï¸ è§¦å‘æ„å»ºå’Œéƒ¨ç½²...")
        
        # è§¦å‘CI/CDæµæ°´çº¿
        build_result = await mcp.jenkins.trigger_build(
            job="myproject-release",
            parameters={
                "VERSION": version,
                "RELEASE_TAG": f"v{version}",
                "DEPLOY_ENVIRONMENT": "production"
            }
        )
        
        # ç­‰å¾…æ„å»ºå®Œæˆ
        print(f"â³ ç­‰å¾…æ„å»ºå®Œæˆ... (Job #{build_result.build_number})")
        build_status = await mcp.jenkins.wait_for_build_completion(
            job="myproject-release",
            build_number=build_result.build_number,
            timeout=1800  # 30åˆ†é’Ÿè¶…æ—¶
        )
        
        if build_status.result != "SUCCESS":
            raise Exception(f"æ„å»ºå¤±è´¥: {build_status.failure_reason}")
        
        print("âœ… æ„å»ºå’Œéƒ¨ç½²æˆåŠŸ")
        
        # ç¬¬5æ­¥ï¼šéƒ¨ç½²åéªŒè¯
        print("ğŸ” æ‰§è¡Œéƒ¨ç½²åéªŒè¯...")
        
        # å¥åº·æ£€æŸ¥
        health_check = await mcp.http_checker.verify_endpoints([
            "https://api.myapp.com/health",
            "https://myapp.com/status"
        ])
        
        if not all(endpoint.healthy for endpoint in health_check.endpoints):
            raise Exception("å¥åº·æ£€æŸ¥å¤±è´¥")
        
        # çƒŸé›¾æµ‹è¯•
        smoke_test_result = await mcp.playwright.run_smoke_tests(
            base_url="https://myapp.com",
            test_suite="release"
        )
        
        if not smoke_test_result.passed:
            raise Exception(f"çƒŸé›¾æµ‹è¯•å¤±è´¥: {smoke_test_result.failed_tests}")
        
        print("âœ… éƒ¨ç½²éªŒè¯é€šè¿‡")
        
        # ç¬¬6æ­¥ï¼šæ›´æ–°é¡¹ç›®ç®¡ç†å·¥å…·
        print("ğŸ“Š æ›´æ–°é¡¹ç›®çŠ¶æ€...")
        
        # å…³é—­Linearä¸­çš„å·²å®ŒæˆIssues
        completed_issues = await mcp.linear.get_issues_for_release(version)
        for issue in completed_issues:
            await mcp.linear.update_issue(
                issue_id=issue.id,
                state="Done",
                comment=f"å·²åœ¨ç‰ˆæœ¬ {version} ä¸­å‘å¸ƒ"
            )
        
        # æ›´æ–°Jiraä¸­çš„ç‰ˆæœ¬çŠ¶æ€
        await mcp.jira.release_version(
            project="MYPROJ",
            version=version,
            release_date=datetime.now().isoformat()
        )
        
        print("âœ… é¡¹ç›®çŠ¶æ€æ›´æ–°å®Œæˆ")
        
        # ç¬¬7æ­¥ï¼šé€šçŸ¥å’Œæ–‡æ¡£
        print("ğŸ“¢ å‘é€å‘å¸ƒé€šçŸ¥...")
        
        # å‘é€å›¢é˜Ÿé€šçŸ¥
        await mcp.slack.send_message(
            channel="#releases",
            blocks=format_release_announcement(
                version=version,
                release_notes=release_notes,
                github_url=github_release.html_url,
                completed_issues=len(completed_issues)
            )
        )
        
        # æ›´æ–°æ–‡æ¡£
        await mcp.confluence.update_release_page(
            page_id="release-history",
            version=version,
            release_data={
                "date": datetime.now().isoformat(),
                "features": extract_features_from_notes(release_notes),
                "bug_fixes": extract_bug_fixes_from_notes(release_notes),
                "github_url": github_release.html_url
            }
        )
        
        # å‘é€ç”¨æˆ·é€šçŸ¥é‚®ä»¶ï¼ˆå¦‚æœæœ‰ç”¨æˆ·é¢å‘çš„æ›´æ–°ï¼‰
        if has_user_facing_changes(release_notes):
            await mcp.sendgrid.send_release_notification(
                template_id="release-notification",
                version=version,
                highlights=extract_user_highlights(release_notes)
            )
        
        print("âœ… é€šçŸ¥å‘é€å®Œæˆ")
        
        # ç¬¬8æ­¥ï¼šè®¾ç½®ç›‘æ§å‘Šè­¦
        print("ğŸ“Š è®¾ç½®å‘å¸ƒç›‘æ§...")
        
        # è®¾ç½®é”™è¯¯ç‡ç›‘æ§
        await mcp.datadog.create_alert(
            name=f"High Error Rate After Release {version}",
            query=f"avg(last_10m):sum:error.rate{{release:{version}}} > 5",
            message="å‘å¸ƒåé”™è¯¯ç‡å¼‚å¸¸ï¼Œéœ€è¦ç«‹å³æ£€æŸ¥",
            tags=[f"release:{version}", "priority:high"]
        )
        
        # è®¾ç½®æ€§èƒ½ç›‘æ§
        await mcp.newrelic.create_alert_policy(
            name=f"Performance Regression - Release {version}",
            conditions=[
                {
                    "type": "response_time",
                    "threshold": "2000ms", 
                    "comparison": "above"
                }
            ]
        )
        
        print("âœ… ç›‘æ§å‘Šè­¦è®¾ç½®å®Œæˆ")
        
        # å‘å¸ƒæˆåŠŸæ€»ç»“
        success_summary = {
            "workflow_id": workflow_id,
            "version": version,
            "release_url": github_release.html_url,
            "build_number": build_result.build_number,
            "completed_issues": len(completed_issues),
            "duration": time.time() - start_time
        }
        
        print(f"""
ğŸ‰ å‘å¸ƒæˆåŠŸï¼
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ç‰ˆæœ¬: {version}
GitHub: {github_release.html_url}
æ„å»º: #{build_result.build_number}
å®ŒæˆIssues: {len(completed_issues)}ä¸ª
æ€»è€—æ—¶: {success_summary['duration']//60:.0f}åˆ†é’Ÿ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        """)
        
        return success_summary
        
    except Exception as e:
        print(f"âŒ å‘å¸ƒå¤±è´¥: {str(e)}")
        
        # å¤±è´¥å¤„ç†æµç¨‹
        await handle_release_failure(
            workflow_id=workflow_id,
            version=version,
            error=str(e),
            stage=determine_failure_stage()
        )
        
        raise


async def handle_release_failure(workflow_id: str, version: str, error: str, stage: str):
    """å‘å¸ƒå¤±è´¥å¤„ç†æµç¨‹"""
    
    print(f"ğŸš¨ å¤„ç†å‘å¸ƒå¤±è´¥...")
    
    # 1. ç«‹å³é€šçŸ¥
    await mcp.slack.send_message(
        channel="#engineering-alerts",
        text="ğŸš¨ **å‘å¸ƒå¤±è´¥è­¦æŠ¥**",
        blocks=[
            {
                "type": "section",
                "text": {"type": "mrkdwn", "text": f"*ç‰ˆæœ¬*: {version}"}
            },
            {
                "type": "section", 
                "text": {"type": "mrkdwn", "text": f"*å¤±è´¥é˜¶æ®µ*: {stage}"}
            },
            {
                "type": "section",
                "text": {"type": "mrkdwn", "text": f"*é”™è¯¯ä¿¡æ¯*: {error}"}
            },
            {
                "type": "actions",
                "elements": [
                    {
                        "type": "button",
                        "text": {"type": "plain_text", "text": "æŸ¥çœ‹æ—¥å¿—"},
                        "url": f"https://logs.myapp.com/workflow/{workflow_id}"
                    }
                ]
            }
        ]
    )
    
    # 2. å›æ»šæ“ä½œï¼ˆå¦‚æœå·²ç»éƒ¨ç½²ï¼‰
    if stage in ["deployment", "post_deployment"]:
        print("ğŸ”„ æ‰§è¡Œè‡ªåŠ¨å›æ»š...")
        
        # è·å–ä¸Šä¸€ä¸ªç¨³å®šç‰ˆæœ¬
        previous_release = await mcp.github.get_previous_release()
        
        # è§¦å‘å›æ»šéƒ¨ç½²
        rollback_result = await mcp.jenkins.trigger_build(
            job="myproject-rollback",
            parameters={
                "ROLLBACK_TO": previous_release.tag_name,
                "REASON": f"Release {version} failed: {error}"
            }
        )
        
        print(f"âœ… å›æ»šå·²è§¦å‘: Job #{rollback_result.build_number}")
    
    # 3. åˆ›å»ºäº‹æ•…æŠ¥å‘Š
    incident_report = await mcp.linear.create_issue(
        title=f"å‘å¸ƒå¤±è´¥äº‹æ•…: {version}",
        description=f"""
## äº‹æ•…æ¦‚è¦
- ç‰ˆæœ¬: {version}
- å·¥ä½œæµID: {workflow_id}
- å¤±è´¥é˜¶æ®µ: {stage}
- é”™è¯¯ä¿¡æ¯: {error}

## å½±å“è¯„ä¼°
- å‘å¸ƒçŠ¶æ€: å¤±è´¥
- ç”Ÿäº§ç¯å¢ƒ: {'éœ€è¦å›æ»š' if stage in ['deployment', 'post_deployment'] else 'æœªå½±å“'}

## åç»­è¡ŒåŠ¨
- [ ] è°ƒæŸ¥å¤±è´¥åŸå› 
- [ ] ä¿®å¤é—®é¢˜  
- [ ] é‡æ–°å‘å¸ƒ
- [ ] æ€»ç»“ç»éªŒæ•™è®­
        """,
        labels=["incident", "release-failure", "high-priority"],
        assignee="release_manager",
        priority="Urgent"
    )
    
    print(f"ğŸ“‹ äº‹æ•…æŠ¥å‘Šå·²åˆ›å»º: {incident_report.identifier}")
```

### 2. æ™ºèƒ½ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ

#### è·¨å¹³å°ç›‘æ§é›†æˆ

```yaml
# ç›‘æ§é›†æˆé…ç½®
monitoring_integration:
  providers:
    # åº”ç”¨æ€§èƒ½ç›‘æ§
    datadog:
      api_key: "${DATADOG_API_KEY}"
      app_key: "${DATADOG_APP_KEY}"
      dashboards:
        - "application-overview"
        - "infrastructure-health"
        - "business-metrics"
      
    # é”™è¯¯ç›‘æ§
    sentry:
      dsn: "${SENTRY_DSN}"
      organization: "myorg"
      projects: ["frontend", "backend", "mobile"]
      
    # åŸºç¡€è®¾æ–½ç›‘æ§
    prometheus:
      endpoints:
        - "http://prometheus:9090"
      metrics:
        - "cpu_usage"
        - "memory_usage"
        - "disk_usage"
        - "network_io"
        
    # æ—¥å¿—ç›‘æ§
    elasticsearch:
      hosts: ["elasticsearch:9200"]
      indices: ["application-*", "system-*"]
      
    # ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§
    mixpanel:
      token: "${MIXPANEL_TOKEN}"
      events: ["user_signup", "purchase", "feature_usage"]

  # å‘Šè­¦è§„åˆ™é…ç½®
  alert_rules:
    - name: "high_error_rate"
      condition: "error_rate > 5% for 5 minutes"
      severity: "critical"
      actions:
        - create_linear_issue
        - notify_slack_channel
        - send_pager_alert
        
    - name: "performance_degradation"
      condition: "response_time_p95 > 2000ms for 10 minutes"
      severity: "warning"
      actions:
        - notify_slack_channel
        - create_datadog_event
        
    - name: "user_satisfaction_drop"
      condition: "user_satisfaction_score < 4.0"
      severity: "high"
      actions:
        - create_linear_issue
        - schedule_team_meeting
        - notify_product_manager

  # è‡ªåŠ¨åŒ–å“åº”
  automation:
    # è‡ªåŠ¨æ‰©å®¹
    auto_scaling:
      triggers:
        - "cpu_usage > 80% for 5 minutes"
        - "memory_usage > 90% for 3 minutes"
      actions:
        - scale_up_instances
        - notify_ops_team
        
    # è‡ªåŠ¨æ¢å¤
    auto_recovery:
      triggers:
        - "service_health_check_failed"
        - "database_connection_lost"
      actions:
        - restart_unhealthy_services
        - switch_to_backup_database
        - create_incident_ticket
```

### 3. æ•°æ®é©±åŠ¨å†³ç­–æ”¯æŒ

#### æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ

```python
async def generate_executive_dashboard():
    """ç”Ÿæˆé«˜ç®¡ä»ªè¡¨æ¿æŠ¥å‘Š"""
    
    print("ğŸ“Š ç”Ÿæˆæ‰§è¡Œå±‚ä»ªè¡¨æ¿...")
    
    # 1. æ”¶é›†ä¸šåŠ¡æŒ‡æ ‡
    business_metrics = await collect_business_metrics()
    
    # ç”¨æˆ·å¢é•¿æ•°æ®
    user_growth = await mcp.mixpanel.get_user_growth_metrics(
        time_range="30d",
        segments=["new_users", "active_users", "retained_users"]
    )
    
    # æ”¶å…¥æ•°æ®
    revenue_data = await mcp.stripe.get_revenue_metrics(
        time_range="30d",
        breakdown=["mrr", "arr", "churn_rate"]
    )
    
    # äº§å“ä½¿ç”¨æ•°æ®
    feature_usage = await mcp.amplitude.get_feature_usage(
        time_range="7d",
        features=["core_features", "premium_features"]
    )
    
    print(f"ğŸ“ˆ ä¸šåŠ¡æŒ‡æ ‡æ”¶é›†å®Œæˆ:")
    print(f"  - æœˆæ´»ç”¨æˆ·: {user_growth.monthly_active_users:,}")
    print(f"  - æœˆåº¦æ”¶å…¥: ${revenue_data.monthly_revenue:,.2f}")
    print(f"  - ç”¨æˆ·ç•™å­˜ç‡: {user_growth.retention_rate:.1%}")
    
    # 2. æ”¶é›†æŠ€æœ¯æŒ‡æ ‡
    tech_metrics = await collect_tech_metrics()
    
    # ç³»ç»Ÿç¨³å®šæ€§
    uptime_data = await mcp.pingdom.get_uptime_stats(
        time_range="30d",
        services=["api", "website", "mobile_api"]
    )
    
    # ä»£ç è´¨é‡
    quality_metrics = await mcp.sonarqube.get_quality_metrics(
        projects=["frontend", "backend"],
        metrics=["coverage", "duplicated_lines", "technical_debt"]
    )
    
    # éƒ¨ç½²é¢‘ç‡
    deployment_stats = await mcp.github.get_deployment_frequency(
        time_range="30d",
        environments=["staging", "production"]
    )
    
    print(f"ğŸ”§ æŠ€æœ¯æŒ‡æ ‡æ”¶é›†å®Œæˆ:")
    print(f"  - ç³»ç»Ÿå¯ç”¨æ€§: {uptime_data.overall_uptime:.2%}")
    print(f"  - ä»£ç è¦†ç›–ç‡: {quality_metrics.test_coverage:.1%}")
    print(f"  - éƒ¨ç½²é¢‘ç‡: {deployment_stats.deployments_per_week}æ¬¡/å‘¨")
    
    # 3. æ”¶é›†å›¢é˜Ÿæ•ˆç‡æ•°æ®
    team_metrics = await collect_team_metrics()
    
    # å¼€å‘æ•ˆç‡
    dev_velocity = await mcp.linear.get_team_velocity(
        team_ids=["frontend", "backend", "mobile"],
        time_range="30d"
    )
    
    # ä»£ç å®¡æŸ¥æ•ˆç‡
    review_metrics = await mcp.github.get_review_metrics(
        time_range="30d",
        metrics=["review_time", "approval_rate", "iteration_count"]
    )
    
    # æ”¯æŒå“åº”æ•ˆç‡
    support_metrics = await mcp.zendesk.get_support_metrics(
        time_range="30d",
        metrics=["response_time", "resolution_time", "satisfaction"]
    )
    
    print(f"ğŸ‘¥ å›¢é˜ŸæŒ‡æ ‡æ”¶é›†å®Œæˆ:")
    print(f"  - å¼€å‘é€Ÿåº¦: {dev_velocity.story_points_per_week}ç‚¹/å‘¨")
    print(f"  - ä»£ç å®¡æŸ¥æ—¶é—´: {review_metrics.avg_review_time}å°æ—¶")
    print(f"  - æ”¯æŒæ»¡æ„åº¦: {support_metrics.satisfaction_score:.1f}/5.0")
    
    # 4. ç”Ÿæˆæ´å¯Ÿå’Œå»ºè®®
    insights = await generate_business_insights(
        business_metrics, tech_metrics, team_metrics
    )
    
    # 5. åˆ›å»ºå¯è§†åŒ–æŠ¥å‘Š
    dashboard_data = {
        "summary": {
            "revenue_growth": calculate_growth_rate(revenue_data),
            "user_growth": calculate_growth_rate(user_growth),
            "system_health": calculate_health_score(uptime_data, quality_metrics),
            "team_efficiency": calculate_efficiency_score(dev_velocity, review_metrics)
        },
        "key_metrics": [
            {"name": "æœˆæ´»ç”¨æˆ·", "value": user_growth.monthly_active_users, "change": "+12.3%"},
            {"name": "æœˆåº¦æ”¶å…¥", "value": f"${revenue_data.monthly_revenue:,.0f}", "change": "+8.7%"},
            {"name": "ç³»ç»Ÿå¯ç”¨æ€§", "value": f"{uptime_data.overall_uptime:.2%}", "change": "+0.1%"},
            {"name": "éƒ¨ç½²é¢‘ç‡", "value": f"{deployment_stats.deployments_per_week}/å‘¨", "change": "+15.2%"}
        ],
        "insights": insights,
        "action_items": generate_action_items(insights),
        "forecast": generate_forecast(business_metrics, tech_metrics)
    }
    
    # 6. æ›´æ–°Confluenceä»ªè¡¨æ¿é¡µé¢
    await mcp.confluence.update_dashboard_page(
        page_id="executive-dashboard",
        data=dashboard_data,
        charts=generate_dashboard_charts(dashboard_data)
    )
    
    # 7. å‘é€é‚®ä»¶æŠ¥å‘Šç»™é«˜ç®¡
    await mcp.sendgrid.send_executive_report(
        recipients=["ceo@company.com", "cto@company.com", "cpo@company.com"],
        subject=f"Executive Dashboard - {datetime.now().strftime('%B %Y')}",
        dashboard_data=dashboard_data
    )
    
    # 8. åœ¨Slackå‘é€æ‘˜è¦
    await mcp.slack.send_message(
        channel="#executive-updates",
        text="ğŸ“Š **æœˆåº¦æ‰§è¡Œæ‘˜è¦å·²æ›´æ–°**",
        blocks=format_executive_summary(dashboard_data)
    )
    
    print("âœ… æ‰§è¡Œå±‚ä»ªè¡¨æ¿ç”Ÿæˆå®Œæˆ")
    
    return dashboard_data

# è‡ªåŠ¨ç”Ÿæˆï¼ˆæ¯æœˆç¬¬ä¸€ä¸ªå·¥ä½œæ—¥ï¼‰
schedule.every().month.on("first_monday").at("08:00").do(generate_executive_dashboard)
```

## MCPæœ€ä½³å®è·µå’Œå®‰å…¨è€ƒè™‘

### 1. å®‰å…¨é…ç½®æœ€ä½³å®è·µ

#### æƒé™æ§åˆ¶å’Œæ•°æ®å®‰å…¨

```yaml
# MCPå®‰å…¨é…ç½®æ¨¡æ¿
security_configuration:
  
  # è®¿é—®æ§åˆ¶
  access_control:
    authentication:
      required: true
      methods: ["oauth", "api_key", "certificate"]
      session_timeout: 3600  # 1å°æ—¶
      
    authorization:
      rbac_enabled: true
      default_role: "read_only"
      roles:
        - name: "read_only"
          permissions: ["read_resources", "view_tools"]
          
        - name: "developer"
          permissions: ["read_resources", "use_tools", "create_issues"]
          
        - name: "admin"
          permissions: ["all"]
          
    api_security:
      rate_limiting:
        enabled: true
        requests_per_minute: 100
        burst_limit: 20
        
      request_validation:
        max_payload_size: "10MB"
        required_headers: ["User-Agent", "Authorization"]
        
      response_filtering:
        remove_sensitive_fields: true
        sanitize_output: true

  # æ•°æ®ä¿æŠ¤
  data_protection:
    encryption:
      at_rest: true
      in_transit: true
      algorithm: "AES-256-GCM"
      
    sensitive_data_handling:
      mask_credentials: true
      mask_pii: true
      audit_access: true
      
    data_retention:
      logs_retention_days: 90
      auth_tokens_ttl: 3600
      cache_ttl: 300

  # ç½‘ç»œå®‰å…¨
  network_security:
    allowed_hosts:
      - "api.github.com"
      - "hooks.slack.com"
      - "api.linear.app"
      - "sentry.io"
      
    blocked_domains:
      - "malicious-site.com"
      - "*.suspicious-domain.com"
      
    ssl_verification: true
    proxy_settings:
      http_proxy: "${HTTP_PROXY}"
      https_proxy: "${HTTPS_PROXY}"
      no_proxy: "localhost,127.0.0.1,*.internal"

  # ç›‘æ§å’Œå®¡è®¡
  monitoring:
    audit_logging:
      enabled: true
      log_all_requests: false  # åªè®°å½•é‡è¦æ“ä½œ
      log_level: "info"
      
    security_events:
      track_failed_auth: true
      track_permission_denied: true
      track_unusual_activity: true
      
    alerting:
      security_alerts_channel: "#security-alerts"
      alert_on_failures: true
      alert_threshold: 5  # è¿ç»­5æ¬¡å¤±è´¥è§¦å‘å‘Šè­¦

  # æ²™ç®±å’Œéš”ç¦»
  sandboxing:
    enabled: true
    resource_limits:
      max_memory: "512MB"
      max_cpu_time: "30s"
      max_network_connections: 10
      
    filesystem_access:
      read_only_paths:
        - "/app/config"
        - "/app/templates"
      restricted_paths:
        - "/etc"
        - "/root"
        - "/home"
```

### 2. æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### ç¼“å­˜å’Œæ‰¹å¤„ç†ä¼˜åŒ–

```python
class MCPOptimizationManager:
    """MCPæ€§èƒ½ä¼˜åŒ–ç®¡ç†å™¨"""
    
    def __init__(self):
        self.cache = TTLCache(maxsize=1000, ttl=300)  # 5åˆ†é’Ÿç¼“å­˜
        self.rate_limiter = TokenBucket(capacity=100, refill_rate=10)
        self.batch_processor = BatchProcessor(batch_size=10, max_wait=1.0)
    
    async def optimized_api_call(self, service: str, method: str, **kwargs):
        """ä¼˜åŒ–çš„APIè°ƒç”¨"""
        
        # 1. ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"{service}:{method}:{hash(frozenset(kwargs.items()))}"
        
        # 2. å°è¯•ä»ç¼“å­˜è·å–
        if cache_key in self.cache:
            print(f"ğŸ¯ ç¼“å­˜å‘½ä¸­: {cache_key}")
            return self.cache[cache_key]
        
        # 3. é€Ÿç‡é™åˆ¶æ£€æŸ¥
        if not await self.rate_limiter.acquire():
            raise Exception("APIè°ƒç”¨é¢‘ç‡é™åˆ¶")
        
        # 4. æ‰§è¡ŒAPIè°ƒç”¨
        try:
            result = await self._execute_api_call(service, method, **kwargs)
            
            # 5. ç¼“å­˜ç»“æœ
            self.cache[cache_key] = result
            
            return result
            
        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {e}")
            raise
    
    async def batch_api_calls(self, calls: List[Dict]):
        """æ‰¹é‡APIè°ƒç”¨ä¼˜åŒ–"""
        
        # æŒ‰æœåŠ¡åˆ†ç»„
        grouped_calls = defaultdict(list)
        for call in calls:
            grouped_calls[call['service']].append(call)
        
        results = []
        
        # å¹¶è¡Œæ‰§è¡Œä¸åŒæœåŠ¡çš„è°ƒç”¨
        tasks = []
        for service, service_calls in grouped_calls.items():
            if hasattr(self, f'_batch_{service}'):
                # ä½¿ç”¨æœåŠ¡ç‰¹å®šçš„æ‰¹å¤„ç†æ–¹æ³•
                batch_method = getattr(self, f'_batch_{service}')
                tasks.append(batch_method(service_calls))
            else:
                # ä½¿ç”¨é€šç”¨æ‰¹å¤„ç†
                tasks.append(self._generic_batch_call(service, service_calls))
        
        batch_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # åˆå¹¶ç»“æœ
        for batch_result in batch_results:
            if isinstance(batch_result, Exception):
                print(f"âš ï¸ æ‰¹å¤„ç†å¤±è´¥: {batch_result}")
                continue
            results.extend(batch_result)
        
        return results
    
    async def _batch_github(self, calls: List[Dict]):
        """GitHubæ‰¹é‡è°ƒç”¨ä¼˜åŒ–"""
        
        # GitHub GraphQLæ‰¹é‡æŸ¥è¯¢
        if all(call['method'] == 'get_issue' for call in calls):
            # æ„å»ºGraphQLæŸ¥è¯¢
            query_parts = []
            for i, call in enumerate(calls):
                alias = f"issue{i}"
                query_parts.append(f"""
                {alias}: issue(number: {call['kwargs']['issue_number']}) {{
                    id
                    title
                    body
                    state
                    labels {{ nodes {{ name }} }}
                    assignees {{ nodes {{ login }} }}
                }}
                """)
            
            full_query = f"""
            query BatchIssues {{
                repository(owner: "{calls[0]['kwargs']['owner']}", name: "{calls[0]['kwargs']['repo']}") {{
                    {' '.join(query_parts)}
                }}
            }}
            """
            
            result = await mcp.github.execute_graphql(full_query)
            
            # è§£ææ‰¹é‡ç»“æœ
            batch_results = []
            repo_data = result['data']['repository']
            for i, call in enumerate(calls):
                alias = f"issue{i}"
                issue_data = repo_data[alias]
                batch_results.append({
                    'call_id': call.get('id'),
                    'result': issue_data
                })
            
            return batch_results
    
    async def _generic_batch_call(self, service: str, calls: List[Dict]):
        """é€šç”¨æ‰¹å¤„ç†å®ç°"""
        
        # é™åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(5)
        
        async def _single_call(call):
            async with semaphore:
                try:
                    result = await self.optimized_api_call(
                        service=call['service'],
                        method=call['method'],
                        **call['kwargs']
                    )
                    return {
                        'call_id': call.get('id'),
                        'result': result,
                        'success': True
                    }
                except Exception as e:
                    return {
                        'call_id': call.get('id'),
                        'error': str(e),
                        'success': False
                    }
        
        results = await asyncio.gather(
            *[_single_call(call) for call in calls],
            return_exceptions=True
        )
        
        return results

# ä½¿ç”¨ç¤ºä¾‹
optimizer = MCPOptimizationManager()

# æ‰¹é‡è·å–GitHub Issues
issue_calls = [
    {'service': 'github', 'method': 'get_issue', 'kwargs': {'owner': 'myorg', 'repo': 'myrepo', 'issue_number': i}}
    for i in range(1, 11)
]

batch_results = await optimizer.batch_api_calls(issue_calls)
```

### 3. æ•…éšœå¤„ç†å’Œæ¢å¤æœºåˆ¶

#### è‡ªåŠ¨æ•…éšœæ¢å¤ç³»ç»Ÿ

```python
class MCPResilienceManager:
    """MCPå¼¹æ€§å’Œæ¢å¤ç®¡ç†å™¨"""
    
    def __init__(self):
        self.circuit_breakers = {}
        self.health_checks = {}
        self.backup_strategies = {}
    
    async def resilient_mcp_call(self, service: str, operation: str, **kwargs):
        """å…·æœ‰å¼¹æ€§çš„MCPè°ƒç”¨"""
        
        # 1. æ£€æŸ¥ç†”æ–­å™¨çŠ¶æ€
        circuit_breaker = self.get_circuit_breaker(service)
        
        if circuit_breaker.is_open():
            print(f"âš¡ {service} æœåŠ¡ç†”æ–­ä¸­ï¼Œå°è¯•é™çº§ç­–ç•¥...")
            return await self.execute_fallback_strategy(service, operation, **kwargs)
        
        try:
            # 2. æ‰§è¡Œå¥åº·æ£€æŸ¥
            if not await self.check_service_health(service):
                raise ServiceUnavailableException(f"{service} æœåŠ¡ä¸å¯ç”¨")
            
            # 3. æ‰§è¡Œä¸»è¦æ“ä½œ
            result = await self._execute_with_retry(service, operation, **kwargs)
            
            # 4. æˆåŠŸæ—¶é‡ç½®ç†”æ–­å™¨
            circuit_breaker.record_success()
            
            return result
            
        except Exception as e:
            # 5. å¤±è´¥æ—¶è®°å½•å¹¶è§¦å‘é™çº§
            circuit_breaker.record_failure()
            
            print(f"âŒ {service} è°ƒç”¨å¤±è´¥: {e}")
            
            # 6. æ‰§è¡Œè‡ªåŠ¨æ¢å¤å°è¯•
            if self.should_attempt_recovery(service, e):
                await self.attempt_service_recovery(service)
            
            # 7. æ‰§è¡Œé™çº§ç­–ç•¥
            return await self.execute_fallback_strategy(service, operation, **kwargs)
    
    async def _execute_with_retry(self, service: str, operation: str, max_retries: int = 3, **kwargs):
        """å¸¦é‡è¯•çš„æ‰§è¡Œ"""
        
        last_exception = None
        
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    # æŒ‡æ•°é€€é¿
                    wait_time = 2 ** attempt
                    print(f"â³ é‡è¯•ç¬¬{attempt}æ¬¡ï¼Œç­‰å¾…{wait_time}ç§’...")
                    await asyncio.sleep(wait_time)
                
                return await self._execute_mcp_operation(service, operation, **kwargs)
                
            except (TimeoutError, ConnectionError) as e:
                last_exception = e
                print(f"âš ï¸ ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥: {e}")
                continue
                
            except Exception as e:
                # éä¸´æ—¶æ€§é”™è¯¯ï¼Œä¸é‡è¯•
                raise e
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        raise last_exception
    
    async def check_service_health(self, service: str) -> bool:
        """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
        
        health_checker = self.health_checks.get(service)
        if not health_checker:
            return True  # æ²¡æœ‰é…ç½®å¥åº·æ£€æŸ¥ï¼Œå‡è®¾å¥åº·
        
        try:
            health_result = await asyncio.wait_for(
                health_checker.check(),
                timeout=5.0  # 5ç§’è¶…æ—¶
            )
            
            return health_result.is_healthy
            
        except asyncio.TimeoutError:
            print(f"âš ï¸ {service} å¥åº·æ£€æŸ¥è¶…æ—¶")
            return False
            
        except Exception as e:
            print(f"âŒ {service} å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    async def execute_fallback_strategy(self, service: str, operation: str, **kwargs):
        """æ‰§è¡Œé™çº§ç­–ç•¥"""
        
        fallback_strategy = self.backup_strategies.get(service, {}).get(operation)
        
        if not fallback_strategy:
            raise ServiceUnavailableException(f"æ— æ³•æ‰§è¡Œ {service}.{operation}ï¼Œä¸”æ²¡æœ‰é…ç½®é™çº§ç­–ç•¥")
        
        strategy_type = fallback_strategy.get('type')
        
        if strategy_type == 'cache':
            # ä»ç¼“å­˜è·å–æ•°æ®
            return await self._get_from_cache(service, operation, **kwargs)
            
        elif strategy_type == 'alternative_service':
            # ä½¿ç”¨æ›¿ä»£æœåŠ¡
            alt_service = fallback_strategy['alternative']
            return await self._execute_mcp_operation(alt_service, operation, **kwargs)
            
        elif strategy_type == 'mock_data':
            # è¿”å›æ¨¡æ‹Ÿæ•°æ®
            return fallback_strategy['mock_response']
            
        elif strategy_type == 'graceful_degradation':
            # ä¼˜é›…é™çº§
            return await self._graceful_degradation_response(service, operation, **kwargs)
            
        else:
            raise ServiceUnavailableException(f"æœªçŸ¥çš„é™çº§ç­–ç•¥: {strategy_type}")
    
    async def attempt_service_recovery(self, service: str):
        """å°è¯•æœåŠ¡æ¢å¤"""
        
        print(f"ğŸ”§ å°è¯•æ¢å¤ {service} æœåŠ¡...")
        
        recovery_strategies = [
            self._clear_service_cache,
            self._reset_connection_pool,
            self._refresh_auth_tokens,
            self._restart_service_connection
        ]
        
        for strategy in recovery_strategies:
            try:
                success = await strategy(service)
                if success:
                    print(f"âœ… {service} æœåŠ¡æ¢å¤æˆåŠŸ")
                    return True
            except Exception as e:
                print(f"âš ï¸ æ¢å¤ç­–ç•¥å¤±è´¥: {e}")
                continue
        
        print(f"âŒ {service} æœåŠ¡æ¢å¤å¤±è´¥")
        return False
    
    async def _clear_service_cache(self, service: str) -> bool:
        """æ¸…ç†æœåŠ¡ç¼“å­˜"""
        try:
            # æ¸…ç†ç›¸å…³ç¼“å­˜
            cache_keys = [key for key in self.cache.keys() if key.startswith(f"{service}:")]
            for key in cache_keys:
                del self.cache[key]
            
            print(f"ğŸ§¹ å·²æ¸…ç† {service} ç¼“å­˜")
            return True
        except Exception:
            return False
    
    async def _reset_connection_pool(self, service: str) -> bool:
        """é‡ç½®è¿æ¥æ± """
        try:
            # é‡ç½®HTTPè¿æ¥æ± 
            if hasattr(self, f'_{service}_client'):
                client = getattr(self, f'_{service}_client')
                await client.close()
                # é‡æ–°åˆ›å»ºè¿æ¥
                setattr(self, f'_{service}_client', self._create_service_client(service))
            
            print(f"ğŸ”„ å·²é‡ç½® {service} è¿æ¥æ± ")
            return True
        except Exception:
            return False
    
    async def _refresh_auth_tokens(self, service: str) -> bool:
        """åˆ·æ–°è®¤è¯ä»¤ç‰Œ"""
        try:
            auth_manager = self.get_auth_manager(service)
            if auth_manager:
                await auth_manager.refresh_tokens()
                print(f"ğŸ”‘ å·²åˆ·æ–° {service} è®¤è¯ä»¤ç‰Œ")
                return True
            return False
        except Exception:
            return False

# é…ç½®é™çº§ç­–ç•¥
resilience_config = {
    "github": {
        "fallback_strategies": {
            "get_issue": {
                "type": "cache",
                "ttl": 3600
            },
            "create_issue": {
                "type": "graceful_degradation",
                "message": "GitHubæš‚æ—¶ä¸å¯ç”¨ï¼ŒIssueå°†åœ¨æœåŠ¡æ¢å¤ååˆ›å»º"
            }
        },
        "health_check": {
            "endpoint": "https://api.github.com/zen",
            "timeout": 5,
            "interval": 30
        }
    },
    "slack": {
        "fallback_strategies": {
            "send_message": {
                "type": "alternative_service",
                "alternative": "email"
            }
        }
    }
}

# ä½¿ç”¨ç¤ºä¾‹
resilience_manager = MCPResilienceManager()
await resilience_manager.configure(resilience_config)

# å¼¹æ€§è°ƒç”¨
result = await resilience_manager.resilient_mcp_call(
    service="github",
    operation="get_issue",
    owner="myorg",
    repo="myrepo",
    issue_number=123
)
```

## æ€»ç»“ï¼šMCPå¼€å¯æ™ºèƒ½åä½œæ–°çºªå…ƒ

é€šè¿‡Claude Codeçš„MCPåè®®ï¼Œä½ å·²ç»æŒæ¡äº†ï¼š

### ğŸ¯ æ ¸å¿ƒä»·å€¼å®ç°

1. **å·¥å…·ç»Ÿä¸€**ï¼šå°†åˆ†æ•£çš„å·¥å…·ç”Ÿæ€æ•´åˆåˆ°å•ä¸€æ™ºèƒ½ç•Œé¢
2. **ä¸Šä¸‹æ–‡è¿è´¯**ï¼šAIåŠ©æ‰‹ç†è§£å®Œæ•´çš„å·¥ä½œæµç¨‹å’Œä¸šåŠ¡é€»è¾‘
3. **è‡ªåŠ¨åŒ–å¢å¼º**ï¼šå¤æ‚è·¨å¹³å°æ“ä½œçš„ä¸€é”®å¼è‡ªåŠ¨åŒ–æ‰§è¡Œ
4. **æ™ºèƒ½æ´å¯Ÿ**ï¼šåŸºäºå¤šæ•°æ®æºçš„æ·±åº¦åˆ†æå’Œå†³ç­–æ”¯æŒ
5. **å¼¹æ€§æ¶æ„**ï¼šä¼ä¸šçº§çš„å®‰å…¨æ€§ã€å¯é æ€§å’Œæ€§èƒ½ä¿éšœ

### âš¡ æ•ˆç‡é©å‘½å¯¹æ¯”

| å·¥ä½œåœºæ™¯ | ä¼ ç»Ÿæ–¹å¼ | MCPé›†æˆ | æ•ˆç‡æå‡ |
|---------|----------|----------|----------|
| Bugåˆ†æè°ƒæŸ¥ | 30-60åˆ†é’Ÿ | 3-5åˆ†é’Ÿ | 10-20å€ |
| é¡¹ç›®çŠ¶æ€åŒæ­¥ | 2-4å°æ—¶ | 5-10åˆ†é’Ÿ | 15-30å€ |
| å‘å¸ƒæµç¨‹æ‰§è¡Œ | 4-8å°æ—¶ | 1-2å°æ—¶ | 3-5å€ |
| æ•°æ®æŠ¥å‘Šç”Ÿæˆ | 1-2å¤© | 10-20åˆ†é’Ÿ | 50-100å€ |
| è·¨å›¢é˜Ÿåä½œ | æ•°å°æ—¶æ²Ÿé€š | å®æ—¶è‡ªåŠ¨åŒ– | æ— é™æå‡ |

### ğŸ› ï¸ MCPå·¥å…·ç”Ÿæ€

- **å¼€å‘å·¥å…·é›†æˆ**ï¼šGitHubã€GitLabã€Bitbucketä»£ç ç®¡ç†
- **é¡¹ç›®ç®¡ç†å¹³å°**ï¼šLinearã€Jiraã€Asanaä»»åŠ¡è·Ÿè¸ª
- **ç›‘æ§å’Œå‘Šè­¦**ï¼šSentryã€DataDogã€New Relicæ€§èƒ½ç›‘æ§
- **é€šä¿¡åä½œ**ï¼šSlackã€Microsoft Teamså›¢é˜Ÿæ²Ÿé€š
- **äº‘æœåŠ¡å¹³å°**ï¼šAWSã€Azureã€GCPåŸºç¡€è®¾æ–½ç®¡ç†

### ğŸš€ æ™ºèƒ½åä½œæ–°æ¨¡å¼

1. **é¢„æµ‹æ€§è¿ç»´**ï¼šAIä¸»åŠ¨è¯†åˆ«é—®é¢˜å¹¶è‡ªåŠ¨ä¿®å¤
2. **æ™ºèƒ½å†³ç­–æ”¯æŒ**ï¼šåŸºäºå®æ—¶æ•°æ®çš„ä¸šåŠ¡æ´å¯Ÿ
3. **æ— ç¼å›¢é˜Ÿåä½œ**ï¼šè·¨å¹³å°ä¿¡æ¯åŒæ­¥å’ŒçŠ¶æ€æ›´æ–°
4. **è‡ªé€‚åº”å·¥ä½œæµ**ï¼šæ ¹æ®æƒ…å†µåŠ¨æ€è°ƒæ•´æ‰§è¡Œç­–ç•¥
5. **æŒç»­ä¼˜åŒ–æ”¹è¿›**ï¼šåŸºäºä½¿ç”¨åé¦ˆçš„ç³»ç»Ÿè‡ªæˆ‘ä¼˜åŒ–

é€šè¿‡MCPåè®®çš„å¼ºå¤§è¿æ¥èƒ½åŠ›ï¼ŒClaude Codeä»å•çº¯çš„ç¼–ç¨‹åŠ©æ‰‹å‡çº§ä¸º**ä½ çš„æ™ºèƒ½å¼€å‘ç”Ÿæ€ä¸­å¿ƒ**ã€‚è¿™ä¸ä»…ä»…æ˜¯å·¥å…·çš„æ•´åˆï¼Œæ›´æ˜¯å·¥ä½œæ–¹å¼çš„æ ¹æœ¬å˜é©â€”â€”è®©AIçœŸæ­£ç†è§£å’Œå‚ä¸ä½ çš„å®Œæ•´ä¸šåŠ¡æµç¨‹ï¼Œå®ç°çœŸæ­£çš„æ™ºèƒ½åŒ–åä½œã€‚

åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢ç´¢å›¢é˜Ÿåä½œé…ç½®ï¼Œå­¦ä¹ å¦‚ä½•åœ¨å¤šäººå¼€å‘ç¯å¢ƒä¸­å‘æŒ¥Claude Codeçš„æœ€å¤§ä»·å€¼ã€‚

## ç›¸å…³æ–‡ç« æ¨è

- [é’©å­Hooksç³»ç»Ÿä¸äº‹ä»¶å¤„ç†](20-é’©å­Hooksç³»ç»Ÿä¸äº‹ä»¶å¤„ç†.md)
- [å›¢é˜Ÿåä½œï¼šå¤šäººå¼€å‘ç¯å¢ƒé…ç½®](23-å›¢é˜Ÿåä½œå¤šäººå¼€å‘ç¯å¢ƒé…ç½®.md)
- [CI/CDé›†æˆï¼šæŒç»­é›†æˆæŒç»­éƒ¨ç½²](24-CICDé›†æˆæŒç»­é›†æˆæŒç»­éƒ¨ç½².md)
- [ä¼ä¸šå®‰å…¨ï¼šæƒé™ç®¡ç†ä¸æ•°æ®ä¿æŠ¤](25-ä¼ä¸šå®‰å…¨æƒé™ç®¡ç†ä¸æ•°æ®ä¿æŠ¤.md)

---

*æœ¬æ–‡æ˜¯ã€ŠClaude Code å®Œæ•´æ•™ç¨‹ç³»åˆ—ã€‹çš„ç¬¬äºŒåäºŒéƒ¨åˆ†ã€‚æŒæ¡äº†MCPåè®®çš„å¼ºå¤§åŠŸèƒ½ï¼Œè®©æˆ‘ä»¬ç»§ç»­æ¢ç´¢å›¢é˜Ÿåä½œçš„æœ€ä½³å®è·µï¼*